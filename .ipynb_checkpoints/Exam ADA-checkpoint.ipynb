{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usual libraries: \n",
    "\n",
    "# Import libraries\n",
    "# Common\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# Merging names. Installation: pip install fuzzywuzzy and pip install fuzzywuzzy[speedup]\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from IPython.core import display as ICD\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# non necessary :\n",
    "\n",
    "# Import libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import itertools\n",
    "from pandas.io.json import json_normalize\n",
    "from pathlib import Path \n",
    "import os \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zampieri/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "# Import ploting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Seaborn parameters\n",
    "sns.set_palette('Reds')\n",
    "sns.set_context(\"notebook\") # possible values are paper, notebook, talk, and poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to plot:\n",
    "\n",
    "# Initialise the subplot\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.set_title('Average new cases')\n",
    "ax2.set_title('Average new deaths')\n",
    "\n",
    "# New cases plot\n",
    "sns.factorplot(x=\"Month\",y='avg_new_cases',hue='Country', data=ebolaf, kind=\"bar\",\\\n",
    "                   palette='hls',legend=True, margin_titles=True,ax=ax1) # hue is how many bars per tick\n",
    "plt.close()\n",
    "\n",
    "# New deaths plot\n",
    "sns.factorplot(x=\"Month\",y='avg_new_deaths',hue='Country', data=ebolaf, kind=\"bar\",\\\n",
    "                   palette='hls',legend=True, margin_titles=True,ax=ax2)\n",
    "\n",
    "plt.close()\n",
    "plt.ylim(0,67.5)\n",
    "plt.legend(loc='upper left')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Possible pd_read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb5 = pd.read_excel(DATA_FOLDER+'/microbiome/MID5.xls', 'Sheet 1',na_values=['NA'], index_col=0, header=None)\n",
    "names.set_index('BARCODE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['cabin'].astype('str') \n",
    "min_data = pd.DataFrame(data.min())\n",
    "myDf.drop(['name','boat','body','home.dest'],axis=1,inplace=True)\n",
    "df['col'].apply(lambda d: pd.to_datatime(d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for matching (instead of networkx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "control_df = df[df['treat']==0].reset_index(drop=True)\n",
    "treat_df = df[df['treat']==1].reset_index(drop=True)\n",
    "\n",
    "def match(treat_df, control_df):\n",
    "    \n",
    "    # we store in prop1, prop2 the vectors of the propensity scorse of the two groups\n",
    "    prop1 = treat_df['propensity score']\n",
    "    prop0 = control_df['propensity score']\n",
    "    \n",
    "    # BUILDING THE COST MATRIX OF THE BIPARTITE GRAPH\n",
    "    cost = np.array([np.abs(p-prop0) for p in prop1])\n",
    "    \n",
    "    # SOLVING THE LINEAR ASSIGNMENT PROBLEM AND OBTAIN THE DESIRED MATCHES!\n",
    "    treat_ind, control_ind = linear_sum_assignment(cost)\n",
    "    \n",
    "    # we extract the matched people from treatment and control group\n",
    "    matched_treat_df = treat_df.loc[treat_ind]\n",
    "    matched_control_df = control_df.loc[control_ind]\n",
    "    # we add a new feature to the treatment: the ID of the matched person in the control group\n",
    "    matched_treat_df['matched control ID']=control_ind\n",
    "    # we merge the dataframe, to have the data of the matched people on the same row!\n",
    "    merged_df = pd.merge(matched_treat_df, matched_control_df,left_on='matched control ID', right_index=True,\\\n",
    "                        suffixes=('_treatment', '_control'))\n",
    "    \n",
    "    # we creae the new feature 'RESULTS OF TREATMENT'\n",
    "    merged_df['RESULT OF TREATMENT']=(merged_df.re78_treatment-merged_df.re74_treatment)-\\\n",
    "                                     (merged_df.re78_control-merged_df.re74_control)\n",
    "    # we create the concatenated dataframe with the matched control and treatment group\n",
    "    concat_df = pd.concat([matched_treat_df, matched_control_df])\n",
    "    \n",
    "    return matched_treat_df,matched_control_df, merged_df, concat_df\n",
    "\n",
    "### LET'S MATCH\n",
    "new_treat_df, new_control_df, matched_df, new_df = match(treat_df, control_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can get rid of all the non-numeric flag that accompany each number:\n",
    "eurodf.replace('u','',regex=True,inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
