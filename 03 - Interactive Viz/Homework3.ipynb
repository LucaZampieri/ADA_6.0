{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Interactive Viz\n",
    "\n",
    "## Deadline\n",
    "\n",
    "Wednesday November 8th, 2017 at 11:59PM\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "- Make sure you push on GitHub your Notebook with all the cells already evaluated\n",
    "- Note that maps do not render in a standard Github environment : you should export them to HTML and link them in your notebook.\n",
    "- Remember that `.csv` is not the only data format. Though they might require additional processing, some formats provide better encoding support.\n",
    "- Don't forget to add a textual description of your thought process, the assumptions you made, and the solution you plan to implement!\n",
    "- Please write all your comments in English, and use meaningful variable names in your code\n",
    "\n",
    "## Background\n",
    "\n",
    "In this homework we will be exploring interactive visualization, which is a key ingredient of many successful data visualizations (especially when it comes to infographics).\n",
    "\n",
    "Unemployment rates are major economic metrics and a matter of concern for governments around the world. Though its definition may seem straightforward at first glance (usually defined as the number of unemployed people divided by the active population), it can be tricky to define consistently. For example, one must define what exactly unemployed means : looking for a job ? Having declared their unemployment ? Currently without a job ? Should students or recent graduates be included ? We could also wonder what the active population is : everyone in an age category (e.g. `16-64`) ? Anyone interested by finding a job ? Though these questions may seem subtle, they can have a large impact on the interpretation of the results : `3%` unemployment doesn't mean much if we don't know who is included in this percentage.\n",
    "\n",
    "In this homework you will be dealing with two different datasets from the statistics offices of the European commission ([eurostat](http://ec.europa.eu/eurostat/data/database)) and the Swiss Confederation ([amstat](https://www.amstat.ch)). They provide a variety of datasets with plenty of information on many different statistics and demographics at their respective scales. Unfortunately, as is often the case is data analysis, these websites are not always straightforward to navigate. They may include a lot of obscure categories, not always be translated into your native language, have strange link structures, â€¦ Navigating this complexity is part of a data scientists' job : you will have to use a few tricks to get the right data for this homework.\n",
    "\n",
    "For the visualization part, install [Folium](https://github.com/python-visualization/folium) (*HINT*: it is not available in your standard Anaconda environment, therefore search on the Web how to install it easily!). Folium's `README` comes with very clear examples, and links to their own iPython Notebooks -- make good use of this information. For your own convenience, in this same directory you can already find two `.topojson` files, containing the geo-coordinates of\n",
    "\n",
    "- European countries (*liberal definition of EU*) (`topojson/europe.topojson.json`, [source](https://github.com/leakyMirror/map-of-europe))\n",
    "- Swiss cantons (`topojson/ch-cantons.topojson.json`)\n",
    "\n",
    "These will be used as an overlay on the Folium maps.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "1. Go to the [eurostat](http://ec.europa.eu/eurostat/data/database) website and try to find a dataset that includes the european unemployment rates at a recent date.\n",
    "\n",
    "   Use this data to build a [Choropleth map](https://en.wikipedia.org/wiki/Choropleth_map) which shows the unemployment rate in Europe at a country level. Think about [the colors you use](https://carto.com/academy/courses/intermediate-design/choose-colors-1/), how you decided to [split the intervals into data classes](http://gisgeography.com/choropleth-maps-data-classification/) or which interactions you could add in order to make the visualization intuitive and expressive. Compare Switzerland's unemployment rate to that of the rest of Europe.\n",
    "\n",
    "2. Go to the [amstat](https://www.amstat.ch) website to find a dataset that includes the unemployment rates in Switzerland at a recent date.\n",
    "\n",
    "   > *HINT* Go to the `details` tab to find the raw data you need. If you do not speak French, German or Italian, think of using free translation services to navigate your way through.\n",
    "\n",
    "   Use this data to build another Choropleth map, this time showing the unemployment rate at the level of swiss cantons. Again, try to make the map as expressive as possible, and comment on the trends you observe.\n",
    "\n",
    "   The Swiss Confederation defines the rates you have just plotted as the number of people looking for a job divided by the size of the active population (scaled by 100). This is surely a valid choice, but as we discussed one could argue for a different categorization.\n",
    "\n",
    "   Copy the map you have just created, but this time don't count in your statistics people who already have a job and are looking for a new one. How do your observations change ? You can repeat this with different choices of categories to see how selecting different metrics can lead to different interpretations of the same data.\n",
    "\n",
    "3. Use the [amstat](https://www.amstat.ch) website again to find a dataset that includes the unemployment rates in Switzerland at recent date, this time making a distinction between *Swiss* and *foreign* workers.\n",
    "\n",
    "   The Economic Secretary (SECO) releases [a monthly report](https://www.seco.admin.ch/seco/fr/home/Arbeit/Arbeitslosenversicherung/arbeitslosenzahlen.html) on the state of the employment market. In the latest report (September 2017), it is noted that there is a discrepancy between the unemployment rates for *foreign* (`5.1%`) and *Swiss* (`2.2%`) workers.\n",
    "\n",
    "   Show the difference in unemployment rates between the two categories in each canton on a Choropleth map (*hint* The easy way is to show two separate maps, but can you think of something better ?). Where are the differences most visible ? Why do you think that is ?\n",
    "\n",
    "   Now let's refine the analysis by adding the differences between age groups. As you may have guessed it is nearly impossible to plot so many variables on a map. Make a bar plot, which is a better suited visualization tool for this type of multivariate data.\n",
    "\n",
    "4. *BONUS*: using the map you have just built, and the geographical information contained in it, could you give a *rough estimate* of the difference in unemployment rates between the areas divided by the [RÃ¶stigraben](https://en.wikipedia.org/wiki/R%C3%B6stigraben)?\n",
    "\n",
    "# Solution\n",
    "\n",
    "Importing all the libraries needed.\n",
    "** For this work we need the library 'jenkspy':  https://pypi.python.org/pypi/jenkspy/0.1.0**\n",
    "\n",
    "To install it type: `pip install jenkspy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import json\n",
    "import branca.colormap as cm # for color steps\n",
    "from IPython.core import display as ICD\n",
    "import folium\n",
    "from folium import plugins\n",
    "import os\n",
    "import jenkspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the topojson files that we are going to use for the choropleth maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JSON_FOLDER = r'topojson/'\n",
    "# europe\n",
    "topojson_europe_path = JSON_FOLDER + r'europe.topojson.json'\n",
    "topojson_europe = json.load(open(topojson_europe_path))\n",
    "# suisse\n",
    "topojson_swiss_path = JSON_FOLDER + r'ch-cantons.topojson.json'\n",
    "topojson_swiss = json.load(open(topojson_swiss_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the tool provided at the following link http://jeffpaine.github.io/geojson-topojson/  we convert the `\\*.topojson` files in `\\*.geojson` format. We put the `\\*.geojson` in the same folder `JSON_FOLDER`.\n",
    "\n",
    "**The geojson will not be used for the chotopleth map, but just to add the popups, since hey are easier to handle with folium**\n",
    "\n",
    "After having obtained such `\\*.geojson` files for both Europe and Suisse, we load them into the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# europe data\n",
    "europe_geojson_path = JSON_FOLDER + r'europe.geojson.json'\n",
    "geojson_europe = json.load(open(europe_geojson_path))\n",
    "\n",
    "# swiss data\n",
    "swiss_geojson_path = JSON_FOLDER + r'ch-cantons.geojson.json'\n",
    "geojson_swiss = json.load(open(swiss_geojson_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: visual analysis of the unemployment in Europe\n",
    "\n",
    "The choice of the dataset has been forced by the need to have also data for Switzerland. the only dataset that we found on the _Eurostat_ website that contained data from Switzerlad is the following:\n",
    "\n",
    "**Long-term unemployment rate, by sex**       _from eurostat_\n",
    "\n",
    "link: http://ec.europa.eu/eurostat/web/products-datasets/-/tsdsc330\n",
    "\n",
    "_Short description:_ the share of long-term unemployment is the share of unemployed persons since 12 months or more in the total active population, expressed as a percentage. The total active population (labour force) is the total number of the employed and unemployed population. The duration of unemployment is defined as the duration of a search for a job or as the period of time since the last job was held (if this period is shorter than the duration of the search for a job).\n",
    "\n",
    "In this dataset, the values come sometimes with a letter next to it: the meaning of such letter is explained hereunder:\n",
    "* **b** break in the time serie\n",
    "* **e** for estimated\n",
    "* **u** low relialability\n",
    "\n",
    "Non avaiable data are indicated with the character semicolumn **' : '**\n",
    "\n",
    "Let's import such data; usual cleaning operations on the dataframe has been commented and described with in-line comments to improve readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>country code</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>...</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>AT</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>BE</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>BG</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>CH</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>CY</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7 u</td>\n",
       "      <td>0.5 u</td>\n",
       "      <td>0.6 u</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex country code 1996  1997  1998  1999  2000   2001   2002  2003  ...   \\\n",
       "0   F           AT  nan   nan   nan   nan   nan    nan    1.1   1.0  ...    \n",
       "1   F           BE  nan   nan   nan   6.0   4.7    3.5    4.3   4.2  ...    \n",
       "2   F           BG  nan   nan   nan   nan   9.4   11.9   11.4   8.6  ...    \n",
       "3   F           CH  nan   nan   nan   nan   nan    nan    nan   nan  ...    \n",
       "4   F           CY  nan   nan   nan   nan   nan    nan    nan   nan  ...    \n",
       "\n",
       "   2007   2008   2009  2010  2011  2012  2013  2014  2015  2016  \n",
       "0   1.5    1.0    1.1   1.0   1.1   1.1   1.2   1.4   1.4   1.7  \n",
       "1   4.3    3.6    3.6   4.1   3.6   3.2   3.7   3.8   3.9   3.8  \n",
       "2   4.5    3.1    3.1   4.4   5.5   5.8   6.6   6.0   5.0   4.1  \n",
       "3   nan    nan    nan   1.9   1.7   1.6   1.7   1.9   1.9   1.9  \n",
       "4  0.7 u  0.5 u  0.6 u  1.3   1.5   3.1   5.6   7.0   6.2   5.1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "eurodf = pd.read_csv(DATA_FOLDER + 'tsdsc330.tsv' , sep='\\t|,|[|]', engine='python')\n",
    "# replace semicolumns with actual NaNs\n",
    "eurodf.replace(to_replace=':', value='nan',inplace=True, regex=True)\n",
    "# dropping useless columns\n",
    "eurodf.drop(['indic_em','age','unit'],inplace=True, axis=1)\n",
    "# renaming columns\n",
    "eurodf.columns.values[1] = 'country code'\n",
    "# eliminating useless tags for our values\n",
    "eurodf.replace(['b','e'],['',''],regex=True,inplace=True)\n",
    "eurodf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Exploratory analysis\n",
    "\n",
    "From the `eurodf.head()` command we immediately notice that:\n",
    "* our data for every nation is split with respect to the categorical variable `\"sex\"` that can assume three different values: `['F','M','T']`.\n",
    "* a lot on NAN values are present in the first years, from 1996 to roughly 2005\n",
    "\n",
    "We are interested in having a look on how many data are considered of \"low reliability\", and as already explained, carachterized by a 'u' next to the value. If the dataset contains a lot of such values, the analysis could loose credibility. We decided to do the following things:\n",
    "* we count how many unceratain data we have, to have an idea of the importance of such values inside the dataset\n",
    "* we plot a heatmap of such uncertain values: in this way we can see diferent things in only one image: how many uncertain data we have compared to others, and also how these data are spread into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mart/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "### creating a dataframe with binary values {0,1} corresponding to safe data and uncertain data\n",
    "### at lines 14-15 we'll plot such heatdf to obtain the desired heatmap\n",
    "heatdf = eurodf[eurodf.columns[2:]]\n",
    "\n",
    "#initializing the counter of uncertain values\n",
    "count = 0\n",
    "# let's count them!\n",
    "for col in eurodf.columns[2:]:\n",
    "    for j,euro_cell in enumerate(eurodf[col]):\n",
    "        if 'u' in euro_cell:\n",
    "            count=count+1\n",
    "            heatdf[col][j]=1\n",
    "        else:\n",
    "            heatdf[col][j]=0\n",
    "print('Inside the dataframe there are %d uncertain values' %count)\n",
    "\n",
    "fig, ax =  plt.subplots(1)\n",
    "ax = sns.heatmap(data=heatdf.astype(int), ax=ax, cbar=False, yticklabels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that:\n",
    "* _the uncertainties in the data are not spread randomly_ across the dataset, but are in particular rows of the dataframe. Since to every nation correspond three rows in the dataframe, we conclude that the uncertainties are due to few, well specified nations, and we can trust the major part of the dataset.\n",
    "* _almost all the uncertain data refers to years from 1996 to 2009_.\n",
    "\n",
    "Thanks to this pattern, we decided to drop all the years before 2010 to have a robust analysis.\n",
    "\n",
    "We continue our exploratory analysis by plotting a timeserie of the unemployment rates for every nation, to have another visual look at our data. From these timeseries we hope to gain some insights on the data and a better understanding of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can get rid of all the non-numeric flag that accompany each number:\n",
    "eurodf.replace('u','',regex=True,inplace=True)\n",
    "# here we keep only the last 8 years, from 2009 to 2016\n",
    "N = 8\n",
    "years = list(eurodf.columns[-N:].astype(int))\n",
    "\n",
    "# we convert the values to floats\n",
    "eurodf[eurodf.columns[2:]]=eurodf[eurodf.columns[2:]].astype(float)\n",
    "\n",
    "#splitting the dataset to\n",
    "totaldf = eurodf[eurodf[\"sex\"]=='T'].reset_index(drop=True)\n",
    "maledf = eurodf[eurodf[\"sex\"]=='M'].reset_index(drop=True)\n",
    "femaledf = eurodf[eurodf[\"sex\"]=='F'].reset_index(drop=True)\n",
    "# Let's plot the time series!\n",
    "fig, axes =  plt.subplots(12,3, figsize=[20,40])\n",
    "for i,ax in enumerate(axes.reshape(-1)):\n",
    "    mpl.style.use('default')\n",
    "    ax.plot_date(years, totaldf.loc[i][-N:], 'C1', label=\"T\")\n",
    "    ax.plot_date(years, maledf.loc[i][-N:], 'C2', label=\"M\")\n",
    "    ax.plot_date(years, femaledf.loc[i][-N:], 'C3', label=\"F\")\n",
    "    ax.set_title(totaldf.loc[i][1])\n",
    "    ax.set_ylim(0,35)\n",
    "    ax.set_xlim(2009,2016)\n",
    "    ax.set_facecolor('white')\n",
    "    #ax.set_xticks(np.arange(1996,2016,4))\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots we see that a big part of the nations present a comparable unemployment rate (between 5% and 10%), and there are a few with a very high or very low unemployment rate. Also, the variations of such value are really important during these 8 years (see the graph of Greece, EL).\n",
    "\n",
    "## 1.2) Visualization of the data using Folium\n",
    "\n",
    "In the cell hereunder we define the code necessary for the display of the Choropleth map using Folium.\n",
    "Further comments are inline, to improve readability of the notebook. Here we just say that:\n",
    "\n",
    "* the total unemployment rate is visualized on the Choropleth map.\n",
    "* to display the data for every year, an interactive map would be needed. Since we couldn't find a way to save this kind of map in `.html`, we opted not to use such a tool and _we limited ourselves to the display of the data regarding a single year (2016)._\n",
    "* default bins for the legend has been utilized (a discussion on this is made afterwards)\n",
    "* **a plugin has been added on the map**: by clicking on each nation, the user can still get an insight on the distinction between male unemployment, female unemployment accessing the raw data corresponding to that nation. In this way any piece information has been lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "\n",
    "# to be decomposed in smaller functions for readability\n",
    "\n",
    "def europe_map(date,bins=None):\n",
    "    ### INPUTS:  date -> the year we want to show on our map\n",
    "    ###          bins -> the list of bins of the legend of the Chloropleth map\n",
    "    ### OUTPUTS: m    -> the map created\n",
    "\n",
    "    m = folium.Map([50,5], tiles='Stamen Toner', zoom_start=4)\n",
    "\n",
    "    m.choropleth(geo_data = json.load(open(topojson_europe_path)),\n",
    "                 data = eurodf.loc[(eurodf['sex']=='T')],\n",
    "                 columns = ['country code', str(date)],\n",
    "                 key_on = 'id',\n",
    "                 threshold_scale = bins,\n",
    "                 topojson = 'objects.europe',\n",
    "                 fill_color = 'YlOrRd', fill_opacity=1,\n",
    "                 line_color = 'black', line_weight = 1, line_opacity=0.9,\n",
    "                 smooth_factor = 1,\n",
    "                 reset = True, # False by default, put true if you wanna remove previous layers\n",
    "                 highlight = True, # hovering\n",
    "                 legend_name='National unemployment in percents')\n",
    "\n",
    "    for feature in geojson_europe['features']:\n",
    "        id_ = feature['id']\n",
    "        name_ = feature['properties']['NAME']\n",
    "        text = name_ #'Country \\n' + id_\n",
    "        additional_text = ''\n",
    "        html = ''\n",
    "        if id_ in list(eurodf['country code']):\n",
    "            female_unemp = eurodf.loc[(eurodf['sex']=='F') & (eurodf['country code']==id_),str(date)].values\n",
    "            male_unemp = eurodf.loc[(eurodf['sex']=='M') & (eurodf['country code']==id_),str(date)].values\n",
    "            total_unemp = eurodf.loc[(eurodf['sex']=='T') & (eurodf['country code']==id_),str(date)].values\n",
    "            d = {'females': female_unemp, 'males': male_unemp,'total': total_unemp}\n",
    "            df_tmp = pd.DataFrame(data=d)\n",
    "            #df_tmp.set_index[['unemployment']]\n",
    "            html = df_tmp.to_html(classes='table table-striped table-hover table-condensed table-responsive')\n",
    "        #elif:\n",
    "\n",
    "        #text += '\\n' + additional_text\n",
    "        pops = folium.GeoJson(\n",
    "           feature,\n",
    "            name = name_,\n",
    "            # overlay=True, ??\n",
    "            style_function=lambda feature: {\n",
    "            'fill_opacity': 0 ,\n",
    "            'fillColor': '#fffff',\n",
    "            'color' : 'black',\n",
    "            'weight' : 0.05,\n",
    "            #'dashArray' : '5, 5',\n",
    "            'highlight' : True # all of these options are not really effectives :'(\n",
    "            },\n",
    "            #highlight_function=highlight_function(feature)\n",
    "        ).add_child(folium.Popup(text + html))\n",
    "\n",
    "        pops.add_to(m) # add popup for that country\n",
    "\n",
    "\n",
    "\n",
    "    plugins.Fullscreen( # to have the full screen option top-right corner\n",
    "        position='topright',\n",
    "        title='Expand me',\n",
    "        title_cancel='Exit me',\n",
    "        force_separate_button=True).add_to(m)\n",
    "\n",
    "    # folium.LayerControl().add_to(m) # to have the button for layer control (top-right corner as well)\n",
    "    return m\n",
    "\n",
    "### ---------------------------------------------------------------------\n",
    "### ------------------------ Let's visualize it! ------------------------\n",
    "### ---------------------------------------------------------------------\n",
    "\n",
    "m = europe_map(2016)\n",
    "m.save(os.path.join('results', 'europe_default.html'))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediately notice that the default subdivision of nations in equally spaced groups is not ideal: the two colours reserved for unemplyment rates between 10 and 16 are not used, since there's no nation in this range!\n",
    "\n",
    "Let's visualize the distribution of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "plt.hist((list(eurodf['2016'].loc[eurodf['sex']=='T'].dropna().astype(float))),bins=np.arange(1,20,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the distribution is really skewed: of course equally spaced bins for the Choropleth map didn't work well. Let's try with the Jensksy algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breaks = jenkspy.jenks_breaks(list(eurodf['2016'].loc[eurodf['sex']=='T'].dropna().astype(float)), nb_class=5)\n",
    "m2 = europe_map(2016, breaks)\n",
    "m2.save(os.path.join('results', 'europe_Jenks.html'))\n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the map obtained is much better: we can notice more differences between the following nations:\n",
    "* Italy, Slovakia and Czech Republic are now distinguished from France and Ireland\n",
    "* still there are a lot of nations in the (1,3) range that cannot be distinguished\n",
    "\n",
    "_As the histogram above suggest, all the countries in the (1,3) range are equally distributed in the subranges (1,2) and (2,3)_; let's try to add such ranges, maybe sacrifying the distinction between Spain and Macedonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breaks = [1,2,3,5,6.7,19.2]\n",
    "m_final = europe_map(2016, breaks)\n",
    "m_final.save(os.path.join('results', 'europe_final.html'))\n",
    "m_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((list(eurodf['2016'].loc[eurodf['sex']=='T'].dropna().astype(float))),bins=breaks, color=['#393E41'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map looks much better! From the histogram of our new subdivision, we can appreciate:\n",
    "* in the first 4 bins there are a comparable number of countries, in between 7 and 10 for each bin\n",
    "* in the last bin there are only 4 nations, but this is the one with the biggest range. It is reasonable to take only few countries into this bin not to loose too mny informations.\n",
    "\n",
    "We can say that at this point we are satisfied of the results obtained and we can proceed to the next task.\n",
    "## 1.3) Comparison of Switzerland and the rest of Europe\n",
    "The last map gives us all the information needed to compare Switzerland to the rest of Europe: Switzerland is in the first bin of our Choroplet map together with countries like Sweden, Norway, Germany, Austria, Czech Republic, and Denmark. With a total unemployment rate in 2016 of 1.8, Switzerland has one of the lowest unemployment rates of Europe.\n",
    "\n",
    "# 2) Unemployment rates in the Swiss cantons\n",
    "\n",
    "Hereunder we prepare the dataset for the analysis of Switzerland unemployment rate. Briefly here's the workflow that we followed:\n",
    "\n",
    "* we import the data obtained in the dataframe `chdf2` that we clean oppurtunately\n",
    "* we define the months of our interest: from September 2016 to September 2017\n",
    "* **Basing our reasoning to the hypotesis stated in the assignment \"The Swiss Confederation defines the rates you have just plotted as the number of people looking for a job divided by the size of the active population (scaled by 100)\"** we use the data avaiable to calculate different unemployment rates, corresponding to the following metrics:\n",
    "    * Unemployed people as provided us by amstat.ch\n",
    "    * Unemployed people without people looking for a different job that still have a job\n",
    "\n",
    "\n",
    "* at the end we define a function `select_data(df,month, column)` capable of extracting a single column `column` of data from our dataframe `chdf2` referred to the month `month` to ease as much as possible the construction of the Choropleth maps. This function takes the adbvantage of the file **cantons_code.csv** that we manually build to associate to every canton name its code. In this way we managed to avoid the use of other boiler code.\n",
    "* we observed that **following that assumptions, the new unemployment rates were sometimes negative!**\n",
    "* ** We revised then our hypothesis** to the following one:\n",
    "\n",
    "### Hypothesis: The Swiss Confederation defines the rates you have just plotted as the number of people looking for a job _that don't have a job_ divided by the size of the active population (scaled by 100)\n",
    "\n",
    "So, to obtain the unemployment rate of people that are looking for a job _whatever they have a job or not_ we had to **sum** to the unemployment rate provided us by amstat.ch the contribute given by \"unemployed people without people looking for a different job that still have a job\", oppurtunately estrapolated by the absolute numbers provided us in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ----------------------------------------------------\n",
    "### FOLLOWING THE ASSUMPTION GIVEN US IN THE ASSIGNMENT\n",
    "### we calculate the new rate, and in the end we'll\n",
    "### observe something strange!!\n",
    "### ----------------------------------------------------\n",
    "\n",
    "#I define this function just for readability\n",
    "def new_unemployment_rate(months, df, new_column_name, category_to_subtract):\n",
    "    ### OUTPUTS: adds a column with the new UNEMPLOYMENT RATE WITHOUT PEOPLE THAT ARE LOOKING FOR A JOB BUT\n",
    "    ### STILL HAVE A JOB based on the HYPOTHESIS OF THE ASSIGNMENT -> (I subtract the contribute of the\n",
    "    ### new category)\n",
    "\n",
    "    for month in months:\n",
    "        df[month,new_column_name] = df[month,'Tasso di disoccupazione']*(df[month,'Disoccupati registrati']-\n",
    "             df[month,category_to_subtract]) /df[month,'Disoccupati registrati']\n",
    "\n",
    "months = ['Settembre 2016',\n",
    "          'Ottobre 2016',\n",
    "          'Novembre 2016',\n",
    "          'Dicembre 2016',\n",
    "          'Gennaio 2017',\n",
    "          'Febbraio 2017',\n",
    "          'Marzo 2017',\n",
    "          'Aprile 2017',\n",
    "          'Maggio 2017',\n",
    "          'Giugno 2017',\n",
    "          'Luglio 2017',\n",
    "          'Agosto 2017',\n",
    "          'Settembre 2017']\n",
    "\n",
    "def select_data(df, when, what):\n",
    "    temp=pd.merge(cantons_code,chdf2[when],left_on='Canton',right_index=True,how='inner')[['code',what]]\n",
    "    temp.rename(columns={what:'unemployment'},inplace=True)\n",
    "    return temp\n",
    "\n",
    "### here we provided a .csv file with the cantons code, necessary for the plot!\n",
    "cantons_code = pd.read_csv(DATA_FOLDER + 'cantons_code.csv')\n",
    "chdf2 = pd.read_excel(DATA_FOLDER + 'ch_punto2.xlsx',header=[0,1])\n",
    "\n",
    "#creating the NEW unemployment rate following the assumption in the assignment\n",
    "new_unemployment_rate(months, chdf2, 'unemployment rate without employed people', 'Persone in cerca d\\'impiego non disoccupate')\n",
    "\n",
    "# dropping useless columns\n",
    "chdf2.drop('mese', axis = 1, level=0,inplace=True)\n",
    "\n",
    "# sorting the index\n",
    "chdf2.sort_index(level=0,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there's no need to understand the code above, just take a look on this examples of of how `select_data` works:\n",
    "\n",
    "### example 1\n",
    "extrecting the original unemployment rate ('Tasso di disoccupazione') for October 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_data(chdf2,'Ottobre 2016', 'Tasso di disoccupazione').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example 2\n",
    "extracting the newly calculated unemployment rate for September 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_data(chdf2,'Settembre 2017', 'unemployment rate without employed people').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are negative values!!!!\n",
    "This could happend only because in our data there are canton with more \"people looking for a job that already have a job\" than \"unemployed people\". This clearly is an absurd if we believe in the hypothesys stated in the assignment. So, we revert what has been done and we follow our hypothesis stated before, that we repeat again:\n",
    "\n",
    "_Hypothesis: The Swiss Confederation defines the rates you have just plotted as **the number of people looking for a job that don't have a job** divided by the size of the active population (scaled by 100)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we drop the clearly wrong results we just obtained\n",
    "chdf2.drop('unemployment rate without employed people',level=1,axis=1,inplace=True)\n",
    "\n",
    "# we redefine of function following the new hypothesys:\n",
    "def new_tasso_add(months, df, new_column_name, category_to_add):\n",
    "    for month in months:\n",
    "        df[month,new_column_name] = df[month,'Tasso di disoccupazione']*(1+df[month,category_to_add]/df[month,'Disoccupati registrati'])\n",
    "\n",
    "# we recalculate them with the new hypothesis\n",
    "new_tasso_add(months, chdf2, 'unemployment rate with employed people', 'Persone in cerca d\\'impiego non disoccupate')\n",
    "\n",
    "#dropping useless columns\n",
    "chdf2.drop(['Persone in cerca d\\'impiego non disoccupate','Disoccupati registrati', 'Disoccupati dei giovani'], axis=1, level=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's visualize everything in a cool Choroplet map!\n",
    "\n",
    "Hereunder the usual helper functions to generate the Choropleth map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#viz funtions\n",
    "\n",
    "def add_features(m,data1,data2,name1='data_1',name2='data_2'):\n",
    "    for feature in geojson_swiss['features']:\n",
    "        id_ = feature['id']\n",
    "        name_ = feature['properties']['name']\n",
    "        text = name_\n",
    "        html = ''\n",
    "        if id_ in list(data1['code']):\n",
    "            tmp1 = data1.loc[data1['code']==id_ , 'unemployment'].values\n",
    "            tmp2 = data2.loc[data2['code']==id_ , 'unemployment'].values\n",
    "            d = {name1 : tmp1, name2 : tmp2, ' ': 'unemployment (%)' }\n",
    "            df_tmp = pd.DataFrame(data=d)\n",
    "            df_tmp.set_index(' ',inplace=True)\n",
    "            html = df_tmp.to_html(classes='table table-striped table-hover table-condensed table-responsive')\n",
    "        #elif:\n",
    "\n",
    "        pops = folium.GeoJson(\n",
    "           feature,\n",
    "            name = name_,\n",
    "            overlay=True,\n",
    "            style_function=lambda feature: {\n",
    "            'fill_opacity': 0 ,\n",
    "            'fillColor': None,\n",
    "            'color' : 'black',\n",
    "            'weight' : 0.05,\n",
    "            #'dashArray' : '5, 5',\n",
    "            'highlight' : True # all of these options are not really effectives :'(\n",
    "            },\n",
    "        ).add_child(folium.Popup(text + html))\n",
    "        pops.add_to(m) # add popup for that country\n",
    "    return m\n",
    "\n",
    "def add_choropleth(m, data, name, bins = None, color='YlOrRd',legend_name='Cantonal unemployment in percents' ):\n",
    "    m.choropleth(geo_data = json.load(open(topojson_swiss_path)),\n",
    "             name = name,\n",
    "             data = data,\n",
    "             columns = ['code', 'unemployment'],\n",
    "             key_on = 'id',\n",
    "             threshold_scale = bins,\n",
    "             topojson = 'objects.cantons',\n",
    "             fill_color = color, fill_opacity=1,\n",
    "             line_color = 'black', line_weight = 1, line_opacity=0.9,\n",
    "             smooth_factor = 1,\n",
    "             reset = False, # False by default, put true if you wanna remove previous layers\n",
    "             highlight = True, # hovering\n",
    "             legend_name= legend_name)\n",
    "    return m\n",
    "\n",
    "def add_fullscreen_button(m):\n",
    "    plugins.Fullscreen( # to have the full screen option top-right corner\n",
    "        position='topright',\n",
    "        title='Expand me',\n",
    "        title_cancel='Exit me',\n",
    "        force_separate_button=True).add_to(m)\n",
    "    return m\n",
    "\n",
    "\n",
    "def create_double_map(data1, data2,\\\n",
    "                        name1, bins, name2,\\\n",
    "                        color='YlOrRd',legend_name='Cantonal unemployment in percents' ):\n",
    "    m = folium.Map([46.5,8], tiles='Mapbox bright', zoom_start=7.4)\n",
    "\n",
    "    add_choropleth(m, data=data1, name=name1, bins = bins,\\\n",
    "                   color=color,legend_name=legend_name )\n",
    "\n",
    "    add_choropleth(m, data=data2, name=name2, bins = bins,\\\n",
    "                   color=color,legend_name=legend_name )\n",
    "\n",
    "    add_features(m,data1,data2,name1,name2)\n",
    "\n",
    "    folium.LayerControl().add_to(m)\n",
    "    add_fullscreen_button(m)\n",
    "    return m\n",
    "\n",
    "def create_single_map(data1,\\\n",
    "                        name1, bins,\\\n",
    "                        color='YlOrRd',legend_name='Cantonal unemployment in percents' ):\n",
    "    m = folium.Map([46.5,8], tiles='Mapbox bright', zoom_start=7.4)\n",
    "\n",
    "    add_choropleth(m, data=data1, name=name1, bins = bins,\\\n",
    "                   color=color,legend_name=legend_name )\n",
    "    add_fullscreen_button(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Let's finally visualize a first Choropleth map of the unemployment rate provided us by default by amstat.ch\n",
    "\n",
    "* with default bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = []\n",
    "data_to_viz = select_data(chdf2,'Settembre 2017',what='Tasso di disoccupazione')\n",
    "m = create_single_map(data1=data_to_viz,\\\n",
    "                  name1='without a job',\\\n",
    "                  bins=None,\\\n",
    "                  color='YlOrRd',legend_name='Cantonal unemployment in percents' )\n",
    "m.save(os.path.join('results', 'suiss_default.html'))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_to_viz['unemployment'],bins=[0.6,1.3,2.1,2.9,3.7,4.5,5.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jensk algorithm\n",
    "As usual, let's apply Jenks algorithm to see a different result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = jenkspy.jenks_breaks(list(data_to_viz['unemployment'].dropna().astype(float)), nb_class=5)\n",
    "m = create_single_map(data1=data_to_viz,\\\n",
    "                  name1='without a job',\\\n",
    "                  bins=bins,\\\n",
    "                  color='YlOrRd',legend_name='Cantonal unemployment in percents')\n",
    "m.save(os.path.join('results', 'suisse_Jensk.html'))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_to_viz['unemployment'],bins=bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "We can see that by jenks algorithm we managed to\n",
    "* reduce the nuber of the classes from 6 to 5\n",
    "* still mantain a good classification of the cantons, but from the histogram we can see how the distribution of the cantons inside the group has been skewed!\n",
    "\n",
    "Prsonally, **this time we prefer the original map with the default bins**. It's more accurate, the number of classes is still not too high (6) and manages to communicate better the differences between the cantons.\n",
    "\n",
    "# 2.2) Compare unemployment rates with and without \"people looking for a job that still have a job\"\n",
    "\n",
    "To compare these two values we plotted _on the same map_ two Chromoplet maps _in two separate layers_: the user thanks to the button on the right can **select the layer and visualize the data he's interested in**. The sudden change in the map of the color helps comparing immediately the change in the two rates.\n",
    "Furthermore, **we added a PopUp** so that if the reader is interested, by clicking on each canton he can access the raw data of the two distributions\n",
    "\n",
    "** How to select the layers**\n",
    "* click on the icon on the right of the screen\n",
    "* select only one between the two options\n",
    "    * without a job\n",
    "    * searching for jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = []\n",
    "\n",
    "m = create_double_map(data1=select_data(chdf2,'Settembre 2017',what='Tasso di disoccupazione'),\\\n",
    "                  data2=select_data(chdf2,'Settembre 2017',what='unemployment rate with employed people'),\\\n",
    "                  name1='without a job',\\\n",
    "                  name2='searching for jobs',bins=[ 0.6,  1.8,  3. ,  4.2,  5.4,  6.6],\\\n",
    "                  color='YlOrRd',legend_name='Cantonal unemployment in percents' )\n",
    "m.save(os.path.join('results', 'suisse_dual_layer_searchingVSwithout.html'))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Comparing the unemployment rate per canton, differencing between swiss people and strangers\n",
    "\n",
    "The strategy to visualize such difference is the same of the previous point: a single map with two layers and a PopUp that the user can select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "chdf = pd.read_excel(DATA_FOLDER + 'chdf_nazionalita.xlsx',header=[0,1])\n",
    "\n",
    "# building the two separate dataframes\n",
    "strangers_df =  pd.DataFrame(chdf['Settembre 2017','Tasso di disoccupazione'][chdf['Nazionalità','Unnamed: 0_level_1']=='stranieri'])\n",
    "strangers_df.columns=strangers_df.columns.droplevel(level=1)\n",
    "strangers_df = pd.merge(strangers_df,cantons_code, left_index=True,right_on = 'Canton', how = 'inner')\n",
    "strangers_df.rename(columns={'Settembre 2017' : 'unemployment'},inplace = True)\n",
    "\n",
    "swissers_df = pd.DataFrame(chdf['Settembre 2017','Tasso di disoccupazione'][chdf['Nazionalità','Unnamed: 0_level_1']=='svizzeri'])\n",
    "swissers_df.columns=swissers_df.columns.droplevel(level=1)\n",
    "swissers_df = pd.merge(swissers_df,cantons_code, left_index=True,right_on = 'Canton', how = 'inner')\n",
    "swissers_df.rename(columns={'Settembre 2017' : 'unemployment'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1, 2,3, 5, 9]\n",
    "m=create_double_map(data1=strangers_df, data2=swissers_df,\\\n",
    "                        name1='foreign', bins=bins, name2='swisss',\\\n",
    "                        color='YlOrRd',legend_name='Cantonal unemployment in percents' )\n",
    "m.save(os.path.join('results', 'suisse_dual_layer_foreignVSsuisse.html'))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### q3 --> BY AGE GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdf_numbers = pd.read_excel(DATA_FOLDER + 'chdf_absolutenumbers.xlsx',header=[0,1])\n",
    "chdf_numbers.drop(['Classi d\\'età 15-24, 15-49, 50 anni e più', 'Unnamed: 2_level_1'], axis=1, level=1,inplace=True)\n",
    "chdf_numbers.drop('mese', axis=1, level=0, inplace=True)\n",
    "chdf_numbers.head()\n",
    "chdf_numbers.columns=chdf_numbers.columns.droplevel(level=1)\n",
    "chdf_numbers.set_index('Nazionalità', append=True, inplace=True)\n",
    "chdf_numbers.set_index('Classi d\\'età 15-24, 15-49, 50 anni e più', append=True, inplace=True)\n",
    "chdf_numbers.drop('Totale',level=2,axis=0,inplace=True)\n",
    "\n",
    "total_unemp_per_canton=chdf_numbers.xs('Totale', level=1, drop_level=False)\n",
    "total_unemp_per_age_category=chdf_numbers.xs('Totale', level=1, drop_level=False)\n",
    "chdf_numbers.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes as input the month we want to extract from our data, and returns a dataframe with:\n",
    "* the data of unemployed strangers and swiss divided in the three age categories\n",
    "* these data are **normalized** with respect to the total number of unemployed _for each canton_. This means that the sum of the six fields of the output dataframe:\n",
    "\n",
    "**(Swiss, age 1)+(Swiss, age 2)+(Swiss, age 3)+(Strangers, age 1)+(Strangers, age 2)+(Strangers, age 3) = 1** _for each canton_\n",
    "\n",
    "This strange normalization procedure is due to the fact that we miss the number of inhabitants per canton for each age category.\n",
    "\n",
    "PROS of this approach:\n",
    "* the barplots are easily readable, since they are pretty much big the same\n",
    "* it's easy to see how unemployed people in each canton are distributed into the 6 categories\n",
    "\n",
    "CONS:\n",
    "* it could be misleading, since the data are not normalized with respect to the total populazion for each category as one could expect.\n",
    "* _the barplots can't be used to compare different cantons_, because of the normalization procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_and_normalize_data(month):    \n",
    "    ### INPUTS: month we are interested to plot\n",
    "    ### OUTPUT: a dataframe normalized as described above in the markdown cell\n",
    "    tot = total_unemp_per_canton[[month]].reset_index(drop=False)[['level_0',month]]\n",
    "    tot.rename(columns={'level_0':'name'},inplace=True)\n",
    "    tot.set_index('name',drop=True, inplace=True)\n",
    "    tmp = chdf_numbers.drop('Totale',level=1,axis=0)\n",
    "    tmp.drop('Totale',level=0,axis=0,inplace=True)\n",
    "    divided = tmp[[month]].divide(tot,level=0)\n",
    "    return divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = select_and_normalize_data('Settembre 2017')\n",
    "\n",
    "ready_to_plot = divided.unstack()\n",
    "ready_to_plot.plot(kind='bar', stacked=True, figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the different cantons, **we provide a second bar plot where the absolute number of unemployed people is represented**. By looking at both graphs, the reader can have then a precise idea of the distribution and differences of unemployment statistics iin between the different cantons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdf_numbers.drop('Totale',level=1,axis=0,inplace=True)\n",
    "chdf_numbers.drop('Totale',level=0,axis=0,inplace=True)\n",
    "ready_to_plot = chdf_numbers[['Settembre 2017']].unstack()\n",
    "ready_to_plot.plot(kind='bar', stacked=True, figsize=(20,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
