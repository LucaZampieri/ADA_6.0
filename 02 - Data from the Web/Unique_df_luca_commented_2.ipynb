{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data from the Web\n",
    "\n",
    "## Deadline\n",
    "Wednesday October 25, 2017 at 11:59PM\n",
    "\n",
    "## Important Notes\n",
    "* Make sure you push on GitHub your Notebook with all the cells already evaluated (i.e., you don't want your colleagues to generate unnecessary Web traffic during the peer review)\n",
    "* Don't forget to add a textual description of your thought process, the assumptions you made, and the solution you plan to implement!\n",
    "* Please write all your comments in English, and use meaningful variable names in your code.\n",
    "\n",
    "## Background\n",
    "In this homework we will extract interesting information from www.topuniversities.com and www.timeshighereducation.com, two platforms that maintain a global ranking of worldwide universities. This ranking is not offered as a downloadable dataset, so you will have to find a way to scrape the information we need!\n",
    "You are not allowed to download manually the entire ranking -- rather you have to understand how the server loads it in your browser. For this task, Postman with the Interceptor extension can help you greatly. We recommend that you watch this [brief tutorial](https://www.youtube.com/watch?v=jBjXVrS8nXs&list=PLM-7VG-sgbtD8qBnGeQM5nvlpqB_ktaLZ&autoplay=1) to understand quickly how to use it.\n",
    "\n",
    "## Assignment\n",
    "1. Obtain the 200 top-ranking universities in www.topuniversities.com ([ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018)). In particular, extract the following fields for each university: name, rank, country and region, number of faculty members (international and total) and number of students (international and total). Some information is not available in the main list and you have to find them in the [details page](https://www.topuniversities.com/universities/ecole-polytechnique-fédérale-de-lausanne-epfl).\n",
    "Store the resulting dataset in a pandas DataFrame and answer the following questions:\n",
    "- Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?\n",
    "- Answer the previous question aggregating the data by (c) country and (d) region.\n",
    "\n",
    "Plot your data using bar charts and describe briefly what you observed.\n",
    "\n",
    "2. Obtain the 200 top-ranking universities in www.timeshighereducation.com ([ranking 2018](http://timeshighereducation.com/world-university-rankings/2018/world-ranking)). Repeat the analysis of the previous point and discuss briefly what you observed.\n",
    "\n",
    "3. Merge the two DataFrames created in questions 1 and 2 using university names. Match universities' names as well as you can, and explain your strategy. Keep track of the original position in both rankings.\n",
    "\n",
    "4. Find useful insights in the data by performing an exploratory analysis. Can you find a strong correlation between any pair of variables in the dataset you just created? Example: when a university is strong in its international dimension, can you observe a consistency both for students and faculty members?\n",
    "\n",
    "5. Can you find the best university taking in consideration both rankings? Explain your approach.\n",
    "\n",
    "Hints:\n",
    "- Keep your Notebook clean and don't print the verbose output of the requests if this does not add useful information for the reader.\n",
    "- In case of tie, use the order defined in the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import collections\n",
    "import string\n",
    "import unidecode # to remove accents\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status code: 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a request\n",
    "url_main = 'https://www.topuniversities.com'  # Found with postman\n",
    "r = requests.get(url_main + '/sites/default/files/qs-rankings-data/357051.txt')\n",
    "print('Response status code: {0}\\n'.format(r.status_code))\n",
    "page_body = r.text\n",
    "\n",
    "# Serialize the json data with json library\n",
    "rank_json = json.loads(page_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build the dataframe\n",
    "rank_df = pd.DataFrame()\n",
    "rank_df = rank_df.from_dict(rank_json['data']).head(200)\n",
    "rank_df.stars\n",
    "rank_df.drop(['logo', 'stars', 'nid','cc', 'score'], axis=1, inplace=True)\n",
    "rank_df.set_index('core_id', inplace=True)\n",
    "rank_df = rank_df[['title', 'rank_display', 'country', 'region', 'url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_find(html_attributes, new_df_column_name, rank_df):\n",
    "    _tag = html_attributes['tag']\n",
    "    _class = html_attributes['class']\n",
    "    # _list is a temporary list that will store the values found and then be converted in the df to be returned.\n",
    "    _list = []\n",
    "    for url in rank_df.url:\n",
    "        # for every url contained in rank_df['url'], perform the corresponding request:\n",
    "        uni_url = requests.get(url_main + url)\n",
    "        uni_body = uni_url.text\n",
    "        soup = BeautifulSoup(uni_body, 'html.parser')\n",
    "        # look for <tag=_tag, class=_class>\n",
    "        soup1 = soup.find(_tag, class_=_class)\n",
    "        # if such tag has been found, look then for <tag=_tag, class='number> where the value \n",
    "        # we're interested in is stored! otherwise append -99\n",
    "        if soup1:\n",
    "            soup2 = soup1.find(_tag, class_='number') \n",
    "            # if such tag has been found, append its value to the _list, otherwise append -99\n",
    "            if soup2:\n",
    "                _list.append({new_df_column_name: soup2.text})\n",
    "            else:\n",
    "                _list.append({new_df_column_name: -99})\n",
    "        else:\n",
    "            _list.append({new_df_column_name: -99})\n",
    "    # convert _list to dataframe and return it\n",
    "    return pd.DataFrame.from_dict(_list).replace({r'\\n': ''},\\\n",
    "                                                 regex=True).replace({r',': ''},\\\n",
    "                                                                     regex=True).apply(pd.to_numeric).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining HTML tag and class attributes that we want to find\n",
    "tofind = [{'tag':'div', 'class': 'total faculty'}, \n",
    "          {'tag':'div', 'class': 'inter faculty'}, \n",
    "          {'tag':'div', 'class': 'total student'}, \n",
    "          {'tag':'div', 'class': 'total inter'}]\n",
    "\n",
    "# creating DataFrame with the data found (NaN values = -99)\n",
    "details_df = pd.concat([my_find(tofind[0], 'fac_memb_tot', rank_df),\n",
    "                        my_find(tofind[1], 'fac_memb_int', rank_df),\n",
    "                        my_find(tofind[2], 'nb_stud_tot', rank_df),\n",
    "                        my_find(tofind[3], 'nb_stud_int', rank_df)], axis=1)\n",
    "\n",
    "# concatenate the DataFrames into a unique one\n",
    "details_df.set_index(rank_df.index, inplace=True)\n",
    "QS_df = pd.concat([rank_df, details_df], axis=1)\n",
    "\n",
    "# cleaning the unique DataFrame (deleting the = in rank_display)\n",
    "QS_df.drop(['url'], axis=1, inplace=True)\n",
    "QS_df.rank_display = QS_df.rank_display.replace({r'=': ''}, regex=True).apply(pd.to_numeric).astype(int)\n",
    "\n",
    "# Creating the faculty_members_ratio and number_of_students ratio\n",
    "QS_df['fac_memb_ratio'] = QS_df.fac_memb_tot / QS_df.nb_stud_tot\n",
    "QS_df['int_stud_ratio'] = QS_df.nb_stud_int / QS_df.nb_stud_tot\n",
    "\n",
    "# Deleting what's useless\n",
    "del details_df, tofind, rank_df, r, page_body, rank_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting the index, dropping the 'core_id' column wich is useless, and renaming the columns\n",
    "# in order to prepare themerge with the corresponding TimesHigherEducation dataframe\n",
    "QS_df.reset_index(inplace = True)\n",
    "QS_df.drop('core_id', axis=1, inplace = True)\n",
    "QS_df.columns = ['QS_name', 'QS_rank', 'country', 'region', 'QS_fac_memb_tot', 'QS_fac_memb_int',\n",
    "                'QS_nb_stud_tot', 'QS_nb_stud_int', 'QS_fac_memb_ratio', 'QS_int_stud_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMES HIGHER EDUCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = <Response [200]> // status_code = 200\n"
     ]
    }
   ],
   "source": [
    "# Making the request, beautifully soupping for extracting the dataframe\n",
    "URL = 'https://www.timeshighereducation.com/sites/default/files/the_data_rankings/'\\\n",
    "                +'world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'\n",
    "r = requests.get(URL)\n",
    "print('r = {r} // status_code = {status}'.format(r=r,status=r.status_code))\n",
    "r.content\n",
    "soupp = BeautifulSoup(r.content,'html.parser')\n",
    "rank_json = json.loads(r.text)\n",
    "THE_df = pd.DataFrame()\n",
    "THE_df = THE_df.from_dict(rank_json['data']).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select columns of our interest and changing their name\n",
    "THE_df = THE_df[['name', 'aliases', 'location', 'rank', 'stats_number_students', 'stats_student_staff_ratio', 'stats_pc_intl_students']]\n",
    "THE_df.columns=['THE_name', 'THE_aliases', 'THE_location', 'THE_rank','THE_nb_stud_tot', 'THE_stats_student_staff_ratio','THE_int_stud_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# still the usual, hard-to-understand cleaning of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THE_int_stud_ratio\n",
    "THE_df['THE_int_stud_ratio'] = THE_df['THE_int_stud_ratio'].str.replace('%', '').astype('double')/100\n",
    "\n",
    "# THE_nb_stud_tot\n",
    "THE_df['THE_nb_stud_tot'] = THE_df['THE_nb_stud_tot'].str.replace(',', '').astype('int')\n",
    "\n",
    "# THE_fac_memb_int is a missing data, I add it just to state it clearly\n",
    "THE_df['THE_fac_memb_int'] = -99\n",
    "\n",
    "# THE_fac_memb_tot\n",
    "THE_df['THE_stats_student_staff_ratio']=THE_df['THE_stats_student_staff_ratio'].astype(float)\n",
    "THE_df['THE_fac_memb_tot'] = THE_df['THE_nb_stud_tot']/THE_df['THE_stats_student_staff_ratio']\n",
    "THE_df['THE_fac_memb_tot'] = THE_df['THE_fac_memb_tot'].astype(int)\n",
    "\n",
    "# THE_nb_stud_int\n",
    "THE_df['THE_nb_stud_int'] = THE_df['THE_nb_stud_tot']*THE_df['THE_int_stud_ratio']\n",
    "THE_df['THE_nb_stud_int'] = THE_df['THE_nb_stud_int'].astype(int)\n",
    "\n",
    "# THE_fac_memb_ratio\n",
    "THE_df['THE_fac_memb_ratio'] = 1/THE_df['THE_stats_student_staff_ratio']\n",
    "THE_df=THE_df.drop('THE_stats_student_staff_ratio', axis=1)\n",
    "\n",
    "# THE_rank\n",
    "THE_df['THE_rank'] = THE_df['THE_rank'].astype(str)\n",
    "THE_df['THE_rank'] = THE_df['THE_rank'].replace({r'=': ''}, regex=True).apply(pd.to_numeric).astype(int)\n",
    "\n",
    "# let's now have a look at the clean THE_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY FUNCTIONS --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return dataframes df1,df2 with only the rows where index in column1 exist also in column2 and vice versa\n",
    "# and also a third dataframe with the non mergeable rows.\n",
    "\n",
    "def exclude_differences(df1,df2,column1,column2):\n",
    "    tmp1 = df1[column1].value_counts().index\n",
    "    tmp2 = df2[column2].value_counts().index\n",
    "    my_diff = list(set(tmp1).symmetric_difference(set(tmp2)))\n",
    "    out_1 = df1.copy()\n",
    "    out_2 = df2.copy()\n",
    "    out_3 = out_1.iloc[0:0,:].copy()\n",
    "    \n",
    "    for loc in my_diff:\n",
    "        # we wanna keep track of non meargeable elements\n",
    "        out_31 = out_1[out_1[column1] == loc] \n",
    "        out_32 = out_2[out_2[column2] == loc]\n",
    "        out_3 = pd.concat([out_3, out_31])\n",
    "        out_3 = pd.concat([out_3, out_32])\n",
    "        # now we get rid of these rows\n",
    "        out_1 = out_1[out_1[column1] != loc] \n",
    "        out_2 = out_2[out_2[column2] != loc]\n",
    "                \n",
    "    return out_1, out_2, out_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merging_by_name(THE,QS,prob_limit):\n",
    "    # creating two lists with the names of the universities from the two datasets\n",
    "    the = THE.copy()\n",
    "    qs = QS.copy()\n",
    "    THE_name = list(the.loc[:,'THE_name'])\n",
    "    QS_name = list(qs.loc[:,'QS_name'])\n",
    "\n",
    "    #initializing a new column of the THE_df with the corresponding QS name found by the matching function\n",
    "    # just to control that everything went smoothly\n",
    "    the['THE_corresponding QS name'] = 'unknown'\n",
    "    the['prob'] = 'unknown'\n",
    "\n",
    "    # MATCHING FUNCTION\n",
    "    # finding the probable corresponding name in the QS dataframe for each university\n",
    "    for i,THE_uni in enumerate(THE_name):\n",
    "        QS_uni, prob=process.extractOne(THE_uni, QS_name, scorer=fuzz.token_sort_ratio)\n",
    "        if prob>=prob_limit: #if prob<87, I observed that the algorithm matches diffeent universities!! 97 is a good limit\n",
    "            the.loc[(the['THE_name']== THE_uni) , \"THE_corresponding QS name\"] = QS_uni\n",
    "            the.loc[(the['THE_name']== THE_uni) , 'prob'] = prob\n",
    "                     \n",
    "    # MERGING        \n",
    "    Unique_df=pd.merge(the,qs, left_on='THE_corresponding QS name', right_on='QS_name', how = 'outer')\n",
    "    return Unique_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_unique_df(THE,QS,prob):\n",
    "    unique_list = []\n",
    "    for loc in QS['country'].value_counts().sort_index().index:\n",
    "        the= THE.loc[THE['THE_location'] == loc , :].copy()\n",
    "        qs  = QS.loc[QS['country'] == loc , :].copy()\n",
    "        unique = merging_by_name(the,qs,prob)\n",
    "        unique = unique.dropna(axis=0,how='any')\n",
    "        unique_list.append(unique)\n",
    "    unique_out = pd.concat(unique_list)\n",
    "    return unique_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_matched_uni(df,name, list_of_matched_uni):\n",
    "    out = df.copy()\n",
    "    for x in out[name]:\n",
    "        if x in list_of_matched_uni:\n",
    "            out.drop(out[out[name] == x].index[0], inplace=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_to_non_mergeable(non_mergeable,THE,QS,errors_THE,errors_QS):\n",
    "    out = non_mergeable.copy()\n",
    "\n",
    "    for x in errors_THE:\n",
    "        out = pd.concat([out,THE.loc[THE['THE_name'] == x]])\n",
    "    for x in errors_QS:\n",
    "        out = pd.concat([out,QS.loc[QS['QS_name'] == x]])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next two functions are for text transformation improve fuzz accuracy, we first provide examples of how the libraries work:\n",
    "\n",
    "fuzz influenced by:  äàö _ \n",
    "\n",
    "fuzz not influenced by:  éè'-()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeaaeou_euE\n",
      "Malaga\n"
     ]
    }
   ],
   "source": [
    "# example of use for the library unidecode\n",
    "\n",
    "accented_string = 'Málaga'\n",
    "# accented_string is of type 'unicode'\n",
    "unaccented_string = unidecode.unidecode(accented_string)\n",
    "# unaccented_string contains 'Malaga'and is of type 'str'\n",
    "print(unidecode.unidecode('äèàäéöû_èüÈ'))\n",
    "print(unidecode.unidecode(accented_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 foe bar\n",
      "paris sorbonne university  paris 4\n",
      "eo\n"
     ]
    }
   ],
   "source": [
    "# example of use for the collections library\n",
    "\n",
    "table = collections.defaultdict(lambda: None)\n",
    "table.update({\n",
    "    ord('é'):'e',\n",
    "    ord('ô'):'o',\n",
    "    ord('ö'):'o',\n",
    "    ord(' '):' ',\n",
    "    ord('\\''):' ',\n",
    "    ord('-'): ' ',\n",
    "    ord('\\N{NO-BREAK SPACE}'): ' ',\n",
    "    ord('\\N{EN SPACE}'): ' ',\n",
    "    ord('\\N{EM SPACE}'): ' ',\n",
    "    ord('\\N{THREE-PER-EM SPACE}'): ' ',\n",
    "    ord('\\N{FOUR-PER-EM SPACE}'): ' ',\n",
    "    ord('\\N{SIX-PER-EM SPACE}'): ' ',\n",
    "    ord('\\N{FIGURE SPACE}'): ' ',\n",
    "    ord('\\N{PUNCTUATION SPACE}'): ' ',\n",
    "    ord('\\N{THIN SPACE}'): ' ',\n",
    "    ord('\\N{HAIR SPACE}'): ' ',\n",
    "    ord('\\N{ZERO WIDTH SPACE}'): ' ',\n",
    "    ord('\\N{NARROW NO-BREAK SPACE}'): ' ',\n",
    "    ord('\\N{MEDIUM MATHEMATICAL SPACE}'): ' ',\n",
    "    ord('\\N{IDEOGRAPHIC SPACE}'): ' ',\n",
    "    ord('\\N{IDEOGRAPHIC HALF FILL SPACE}'): ' ',\n",
    "    ord('\\N{ZERO WIDTH NO-BREAK SPACE}'): ' ',\n",
    "    ord('\\N{TAG SPACE}'): ' ',\n",
    "    })\n",
    "table.update(dict(zip(map(ord,string.ascii_uppercase), string.ascii_lowercase)))\n",
    "table.update(dict(zip(map(ord,string.ascii_lowercase), string.ascii_lowercase)))\n",
    "table.update(dict(zip(map(ord,string.digits), string.digits)))\n",
    "\n",
    "print('123 fôé BAR҉'.translate(table,))\n",
    "print('Paris-Sorbonne University – Paris 4'.translate(table,))\n",
    "print('éöàäèüÒàèò'.translate(table,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_accent_in_name(df,name):\n",
    "    out=df#.copy()\n",
    "    for x in out[name]:\n",
    "        x = unidecode.unidecode(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_characters_in_name(df,name):\n",
    "    out=df.copy()\n",
    "    for x in out[name]:\n",
    "        x = x.translate(table,)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Those where our dataset, from now we try to merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there is not the same set of countries in the two ranking. The universities that come from a country not present in the other dataset are thus considered not-mergeable. Note the we replaced \"Russian federation \" by \"Russia\" to have a match, assuming that they are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is my set of country present in only one of the rankings:\n",
      " ['Malaysia', 'Chile', 'Israel', 'Brazil', 'India', 'Argentina', 'Mexico', 'Luxembourg', 'Saudi Arabia']\n"
     ]
    }
   ],
   "source": [
    "# Set russian federation equal russia for comparing countries\n",
    "THE_df.loc[THE_df['THE_location']=='Russian Federation','THE_location']='Russia'\n",
    "\n",
    "# find differences in listed countries\n",
    "tmp1 = QS_df['country'].value_counts().index\n",
    "tmp2 = THE_df['THE_location'].value_counts().index\n",
    "my_diff = list(set(tmp1).symmetric_difference(set(tmp2)))\n",
    "print('Here is my set of country present in only one of the rankings:\\n',my_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 remove unis of countries that are not in both rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QS_df remaining rows:  187     THE_df remaining rows:  199\n",
      "Rows in non-mergeable:  14\n"
     ]
    }
   ],
   "source": [
    "QS_step1, THE_step1, non_mergeable = exclude_differences(QS_df,THE_df,'country','THE_location')\n",
    "\n",
    "print('QS_df remaining rows: ',QS_step1.shape[0],'    THE_df remaining rows: ',THE_step1.shape[0])\n",
    "print('Rows in non-mergeable: ',non_mergeable.shape[0])\n",
    "QS_step1.sort_values('country',inplace=True)\n",
    "THE_step1.sort_values('THE_location',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note that non_meargeable contains only a subset of all the non-meargeables rows, we will append rows to it as the analysis continues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 take out 100% fitting unis names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged rows at this step:  107\n",
      "Non mergeable dataframe #rows:  14\n",
      "THE before:  199    THE after:  92\n",
      "QS before:  187    QS after:  80\n"
     ]
    }
   ],
   "source": [
    "Unique_df = create_unique_df(THE_step1,QS_step1,100)\n",
    "\n",
    "# list of matched unis by ranking\n",
    "QS_matched_uni = list(Unique_df['QS_name'])\n",
    "THE_matched_uni = list(Unique_df['THE_name'])\n",
    "\n",
    "# update the remaining ranking dataframes\n",
    "THE_step2 = drop_matched_uni(THE_step1,'THE_name',THE_matched_uni)\n",
    "QS_step2 = drop_matched_uni(QS_step1,'QS_name', QS_matched_uni)\n",
    "\n",
    "# print to check that the dataframes have the correct size:\n",
    "print('merged rows at this step: ',Unique_df.shape[0])\n",
    "print('Non mergeable dataframe #rows: ',non_mergeable.shape[0])\n",
    "print('THE before: ',THE_step1.shape[0],'   THE after: ',THE_step2.shape[0])\n",
    "print('QS before: ',QS_step1.shape[0],'   QS after: ',QS_step2.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 go to 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged rows at this step:  37\n",
      "Non mergeable dataframe #rows:  14\n",
      "THE before:  92    THE after:  55\n",
      "QS before:  80    QS after:  43\n"
     ]
    }
   ],
   "source": [
    "THE_step2_tmp = remove_accent_in_name(THE_step2,'THE_name') # try to remove accents\n",
    "QS_step2_tmp = remove_accent_in_name(QS_step2,'QS_name') # but without succes\n",
    "\n",
    "Unique_df2 = create_unique_df(THE_step2_tmp,QS_step2_tmp,90) #90 since 100 gave nothing\n",
    "\n",
    "# list of matched unis by ranking (at this step)\n",
    "THE_matched_uni = list(Unique_df2['THE_name'])\n",
    "QS_matched_uni = list(Unique_df2['QS_name'])\n",
    "\n",
    "# update the remaining ranking dataframes\n",
    "THE_step3 = drop_matched_uni(THE_step2,'THE_name',THE_matched_uni)\n",
    "QS_step3 = drop_matched_uni(QS_step2,'QS_name', QS_matched_uni)\n",
    "\n",
    "# usual cross check\n",
    "print('merged rows at this step: ',Unique_df2.shape[0])\n",
    "print('Non mergeable dataframe #rows: ',non_mergeable.shape[0])\n",
    "print('THE before: ',THE_step2.shape[0],'   THE after: ',THE_step3.shape[0])\n",
    "print('QS before: ',QS_step2.shape[0],'   QS after: ',QS_step3.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 go to 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged rows at this step:  8\n",
      "Non mergeable dataframe #rows:  16\n",
      "THE before:  55    THE after:  46\n",
      "QS before:  43    QS after:  34\n"
     ]
    }
   ],
   "source": [
    "THE_step3_tmp = remove_characters_in_name(THE_step3,'THE_name') # tried to remove special characters\n",
    "QS_step3_tmp = remove_characters_in_name(QS_step3,'QS_name') # doesn't work though\n",
    "\n",
    "Unique_df3 = create_unique_df(THE_step3_tmp,QS_step3_tmp,80) \n",
    "\n",
    "# errors made\n",
    "errors = [\"Trinity College Dublin\",'University College Dublin']\n",
    "\n",
    "# update the non-mergeable dataframe\n",
    "non_mergeable = pd.concat([non_mergeable,THE_step3.loc[THE_step3['THE_name'] == \"Trinity College Dublin\"]]) \n",
    "non_mergeable = pd.concat([non_mergeable,QS_step3.loc[QS_step3['QS_name'] == \"University College Dublin\"]]) \n",
    "\n",
    "Unique_df3 = Unique_df3.loc[Unique_df3['THE_name'] != \"Trinity College Dublin\"] #the only one with an error\n",
    "\n",
    "# list of matched unis by ranking (at this step)\n",
    "THE_matched_uni = list(Unique_df3['THE_name'])  + errors\n",
    "QS_matched_uni = list(Unique_df3['QS_name']) + errors\n",
    "\n",
    "# update the remaining ranking dataframes\n",
    "THE_step4 = drop_matched_uni(THE_step3,'THE_name',THE_matched_uni)\n",
    "QS_step4 = drop_matched_uni(QS_step3,'QS_name', QS_matched_uni)\n",
    "\n",
    "# remove duplicates ()usefull mainly if we runs multiples times this cell\n",
    "non_mergeable = non_mergeable.drop_duplicates()\n",
    "\n",
    "# usual cross check \n",
    "print('merged rows at this step: ',Unique_df3.shape[0])\n",
    "print('Non mergeable dataframe #rows: ',non_mergeable.shape[0])\n",
    "print('THE before: ',THE_step3.shape[0],'   THE after: ',THE_step4.shape[0])\n",
    "print('QS before: ',QS_step3.shape[0],'   QS after: ',QS_step4.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5 go to 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged rows at this step:  3\n",
      "Non mergeable dataframe #rows:  22\n",
      "THE before:  46    THE after:  39\n",
      "QS before:  34    QS after:  29\n"
     ]
    }
   ],
   "source": [
    "# df created with the matching function, but some errors are present\n",
    "Unique_df4 = create_unique_df(THE_step4,QS_step4,70) \n",
    "\n",
    "# errors at this step\n",
    "errors = ['University of Sussex','University of Reading',\\\n",
    "          'University of East Anglia','University of Bath',\\\n",
    "          'University of Leicester','University of Dundee']\n",
    "\n",
    "# errors by ranking\n",
    "errors_THE = ['University of Sussex','University of East Anglia','University of Dundee','University of Leicester']\n",
    "errors_QS = ['University of Reading','University of Bath']\n",
    "\n",
    "# clean the unique_df from its errors\n",
    "for x in Unique_df4['QS_name']:\n",
    "    if x in errors:\n",
    "        Unique_df4 = Unique_df4[Unique_df4['QS_name'] != x]\n",
    "for x in Unique_df4['THE_name']:\n",
    "    if x in errors:\n",
    "        Unique_df4 = Unique_df4[Unique_df4['THE_name'] != x]\n",
    "\n",
    "#update non mergeable df\n",
    "non_mergeable = append_to_non_mergeable(non_mergeable,THE_step4,QS_step4,\\\n",
    "                                                    errors_THE,errors_QS)\n",
    "#drop duplicates\n",
    "non_mergeable = non_mergeable.drop_duplicates()\n",
    "\n",
    "# list of matched unis by ranking (at this step)\n",
    "THE_matched_uni = list(Unique_df4['THE_name'])  + errors_THE\n",
    "QS_matched_uni = list(Unique_df4['QS_name']) + errors_QS\n",
    "\n",
    "# update the remaining ranking dataframes\n",
    "THE_step5 = drop_matched_uni(THE_step4,'THE_name',THE_matched_uni)\n",
    "QS_step5 = drop_matched_uni(QS_step4,'QS_name', QS_matched_uni)\n",
    "\n",
    "# usual cross check \n",
    "print('merged rows at this step: ',Unique_df4.shape[0])\n",
    "print('Non mergeable dataframe #rows: ',non_mergeable.shape[0])\n",
    "print('THE before: ',THE_step4.shape[0],'   THE after: ',THE_step5.shape[0])\n",
    "print('QS before: ',QS_step4.shape[0],'   QS after: ',QS_step5.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final STEP all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged rows at this step:  4\n",
      "Non mergeable dataframe #rows:  82\n",
      "THE before:  39    THE after:  35\n",
      "QS before:  29    QS after:  25\n"
     ]
    }
   ],
   "source": [
    "# create merged dataframe with matching function. But some errors are present\n",
    "Unique_df5 = create_unique_df(THE_step5,QS_step5,10)\n",
    "\n",
    "# correct matchings for THE_ranking (since they are unique due to our merging function)\n",
    "rights = ['University of Tübingen','LMU Munich','University of Freiburg','Scuola Superiore Sant’Anna']\n",
    "\n",
    "# errors made: (incorrect matching)\n",
    "errors = list(set(rights).symmetric_difference(set(list(Unique_df5['THE_name']))))\n",
    "\n",
    "for x in errors:\n",
    "    Unique_df5 = Unique_df5[Unique_df5['THE_name'] != x] \n",
    "\n",
    "\n",
    "# list of matched unis by ranking (at this step)\n",
    "THE_matched_uni = list(Unique_df5['THE_name']) \n",
    "QS_matched_uni = list(Unique_df5['QS_name']) \n",
    "\n",
    "# update the remaining ranking dataframes\n",
    "THE_step6 = drop_matched_uni(THE_step5,'THE_name',THE_matched_uni)\n",
    "QS_step6 = drop_matched_uni(QS_step5,'QS_name', QS_matched_uni)\n",
    "\n",
    "# update non_mergeables unis dataframe\n",
    "non_mergeable = pd.concat([non_mergeable,THE_step6,QS_step6])\n",
    "non_mergeable = non_mergeable.drop_duplicates()\n",
    "\n",
    "# usual cross check \n",
    "print('merged rows at this step: ',Unique_df5.shape[0])\n",
    "print('Non mergeable dataframe #rows: ',non_mergeable.shape[0])\n",
    "print('THE before: ',THE_step5.shape[0],'   THE after: ',THE_step6.shape[0])\n",
    "print('QS before: ',QS_step5.shape[0],'   QS after: ',QS_step6.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final check: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged:  159   non-merged 82 \n",
      "missing 0\n",
      "\n",
      "if 0 missing, it is probable the merge is successfull\n"
     ]
    }
   ],
   "source": [
    "merged_df_ori = pd.concat([Unique_df,Unique_df2,Unique_df3,Unique_df4,Unique_df5])\n",
    "num_merged = merged_df.shape[0]\n",
    "\n",
    "non_mergeable = non_mergeable.drop_duplicates()\n",
    "num_non_merged = non_mergeable.shape[0]\n",
    "print ('merged: ',num_merged,'  non-merged',num_non_merged,'\\nmissing',(200-num_merged)*2-num_non_merged)\n",
    "print('\\nif 0 missing, it is probable the merge is successfull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FROM NOW IT IS ORIGINAL WORK AGAIN, we can put it after the one of martino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df_ori.copy()\n",
    "\n",
    "merged_df = merged_df[['THE_name', 'THE_rank','QS_rank','country','region',\\\n",
    "                       'THE_nb_stud_tot','QS_nb_stud_tot', 'THE_int_stud_ratio', 'QS_int_stud_ratio',\\\n",
    "                       'THE_fac_memb_int','QS_fac_memb_int','THE_fac_memb_tot','QS_fac_memb_tot',\\\n",
    "                       'THE_nb_stud_int','QS_nb_stud_int', 'THE_fac_memb_ratio','QS_fac_memb_ratio']]\n",
    "\n",
    "merged_df.columns = [['University', 'THE_rank','QS_rank','country','region',\\\n",
    "                       'THE_nb_stud_tot','QS_nb_stud_tot', 'THE_int_stud_ratio', 'QS_int_stud_ratio',\\\n",
    "                       'THE_fac_memb_int','QS_fac_memb_int','THE_fac_memb_tot','QS_fac_memb_tot',\\\n",
    "                       'THE_nb_stud_int','QS_nb_stud_int', 'THE_fac_memb_ratio','QS_fac_memb_ratio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall that THE_fac_memb_int has been set to -99 since the values where non-sense. When averaging between the two rankings, we will take only the value from QS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the one with all the info\n",
    "merged_df_final = merged_df.copy()\n",
    "# the one with averaged info\n",
    "merged_df_avg = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_avg['nb_stud_tot'] = (merged_df_avg['THE_nb_stud_tot'] + merged_df_avg['QS_nb_stud_tot'])/2\n",
    "merged_df_avg['int_stud_ratio'] = (merged_df_avg['THE_int_stud_ratio'] + merged_df_avg['QS_int_stud_ratio'])/2\n",
    "merged_df_avg['fac_memb_int'] = merged_df_avg['QS_fac_memb_int'] # since no fac_member_ratio\n",
    "merged_df_avg['fac_memb_tot'] = (merged_df_avg['THE_fac_memb_tot'] + merged_df_avg['QS_fac_memb_tot'])/2\n",
    "merged_df_avg['nb_stud_int'] = (merged_df_avg['THE_nb_stud_int'] + merged_df_avg['QS_nb_stud_int'])/2\n",
    "merged_df_avg['fac_memb_ratio'] = (merged_df_avg['THE_fac_memb_ratio'] + merged_df_avg['QS_fac_memb_ratio'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_avg = merged_df_avg[['University', 'THE_rank', 'QS_rank', 'country', 'region',\\\n",
    "                               'nb_stud_tot', 'int_stud_ratio', 'fac_memb_int', 'fac_memb_tot',\\\n",
    "                               'nb_stud_int', 'fac_memb_ratio']].sort_values('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>THE_rank</th>\n",
       "      <th>QS_rank</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>nb_stud_tot</th>\n",
       "      <th>int_stud_ratio</th>\n",
       "      <th>fac_memb_int</th>\n",
       "      <th>fac_memb_tot</th>\n",
       "      <th>nb_stud_int</th>\n",
       "      <th>fac_memb_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monash University</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>52139.5</td>\n",
       "      <td>0.319148</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>16847.0</td>\n",
       "      <td>0.042730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Adelaide</td>\n",
       "      <td>134.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>21240.5</td>\n",
       "      <td>0.321008</td>\n",
       "      <td>633.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>6818.0</td>\n",
       "      <td>0.055279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Queensland</td>\n",
       "      <td>65.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>38232.5</td>\n",
       "      <td>0.268944</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>2124.5</td>\n",
       "      <td>10275.5</td>\n",
       "      <td>0.056116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>University of Western Australia</td>\n",
       "      <td>111.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>18659.0</td>\n",
       "      <td>0.248442</td>\n",
       "      <td>809.0</td>\n",
       "      <td>1140.5</td>\n",
       "      <td>4635.5</td>\n",
       "      <td>0.061250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Australian National University</td>\n",
       "      <td>48.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>15214.0</td>\n",
       "      <td>0.367183</td>\n",
       "      <td>927.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>5573.0</td>\n",
       "      <td>0.081301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of New South Wales</td>\n",
       "      <td>85.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>39958.5</td>\n",
       "      <td>0.349620</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>2213.5</td>\n",
       "      <td>13968.5</td>\n",
       "      <td>0.055475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University of Sydney</td>\n",
       "      <td>61.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>45615.5</td>\n",
       "      <td>0.342420</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>2711.0</td>\n",
       "      <td>15643.0</td>\n",
       "      <td>0.059139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Melbourne</td>\n",
       "      <td>32.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>42149.0</td>\n",
       "      <td>0.413717</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>2447.0</td>\n",
       "      <td>17438.0</td>\n",
       "      <td>0.058044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Vienna</td>\n",
       "      <td>165.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Europe</td>\n",
       "      <td>40671.0</td>\n",
       "      <td>0.287374</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2555.5</td>\n",
       "      <td>11832.5</td>\n",
       "      <td>0.061141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghent University</td>\n",
       "      <td>107.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Europe</td>\n",
       "      <td>35938.5</td>\n",
       "      <td>0.102352</td>\n",
       "      <td>482.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>3678.0</td>\n",
       "      <td>0.048959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KU Leuven</td>\n",
       "      <td>47.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Europe</td>\n",
       "      <td>44975.0</td>\n",
       "      <td>0.151046</td>\n",
       "      <td>784.0</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>6793.5</td>\n",
       "      <td>0.041091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Université Catholique de Louvain</td>\n",
       "      <td>129.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Europe</td>\n",
       "      <td>24364.0</td>\n",
       "      <td>0.187021</td>\n",
       "      <td>406.0</td>\n",
       "      <td>932.5</td>\n",
       "      <td>4556.5</td>\n",
       "      <td>0.038334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>McGill University</td>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>29888.5</td>\n",
       "      <td>0.295412</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>2986.0</td>\n",
       "      <td>8792.0</td>\n",
       "      <td>0.100811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Alberta</td>\n",
       "      <td>119.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>32100.0</td>\n",
       "      <td>0.259120</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>2531.0</td>\n",
       "      <td>8318.0</td>\n",
       "      <td>0.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of British Columbia</td>\n",
       "      <td>34.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>51119.5</td>\n",
       "      <td>0.258088</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>3757.0</td>\n",
       "      <td>13217.5</td>\n",
       "      <td>0.073781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McMaster University</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>23697.5</td>\n",
       "      <td>0.149846</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>3550.5</td>\n",
       "      <td>0.088402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Montreal</td>\n",
       "      <td>108.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>40064.5</td>\n",
       "      <td>0.233849</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>2416.5</td>\n",
       "      <td>9355.5</td>\n",
       "      <td>0.060684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Toronto</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>70817.0</td>\n",
       "      <td>0.236717</td>\n",
       "      <td>3905.0</td>\n",
       "      <td>6646.5</td>\n",
       "      <td>16856.0</td>\n",
       "      <td>0.093082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zhejiang University</td>\n",
       "      <td>177.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>45460.0</td>\n",
       "      <td>0.086583</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>4028.0</td>\n",
       "      <td>3814.0</td>\n",
       "      <td>0.090601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University of Science and Technology of China</td>\n",
       "      <td>132.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>16032.0</td>\n",
       "      <td>0.032091</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1973.5</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.123101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fudan University</td>\n",
       "      <td>116.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>30997.0</td>\n",
       "      <td>0.130316</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>3376.0</td>\n",
       "      <td>3982.5</td>\n",
       "      <td>0.110603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peking University</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>42136.0</td>\n",
       "      <td>0.164132</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>4959.5</td>\n",
       "      <td>6915.5</td>\n",
       "      <td>0.117707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tsinghua University</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>39194.5</td>\n",
       "      <td>0.101088</td>\n",
       "      <td>932.0</td>\n",
       "      <td>4289.0</td>\n",
       "      <td>3930.0</td>\n",
       "      <td>0.112337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shanghai Jiao Tong University</td>\n",
       "      <td>188.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>38109.5</td>\n",
       "      <td>0.066706</td>\n",
       "      <td>887.0</td>\n",
       "      <td>3275.5</td>\n",
       "      <td>2547.5</td>\n",
       "      <td>0.085839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nanjing University</td>\n",
       "      <td>169.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>32975.5</td>\n",
       "      <td>0.095545</td>\n",
       "      <td>617.0</td>\n",
       "      <td>2402.5</td>\n",
       "      <td>3152.5</td>\n",
       "      <td>0.072894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical University of Denmark</td>\n",
       "      <td>153.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Europe</td>\n",
       "      <td>8713.0</td>\n",
       "      <td>0.238157</td>\n",
       "      <td>966.0</td>\n",
       "      <td>1770.5</td>\n",
       "      <td>2074.5</td>\n",
       "      <td>0.202561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aarhus University</td>\n",
       "      <td>109.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Europe</td>\n",
       "      <td>25696.5</td>\n",
       "      <td>0.131723</td>\n",
       "      <td>602.0</td>\n",
       "      <td>2037.5</td>\n",
       "      <td>3391.0</td>\n",
       "      <td>0.079120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Copenhagen</td>\n",
       "      <td>109.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Europe</td>\n",
       "      <td>31257.0</td>\n",
       "      <td>0.127334</td>\n",
       "      <td>2336.0</td>\n",
       "      <td>7448.0</td>\n",
       "      <td>3969.0</td>\n",
       "      <td>0.238440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aalto University</td>\n",
       "      <td>190.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>12445.5</td>\n",
       "      <td>0.175368</td>\n",
       "      <td>370.0</td>\n",
       "      <td>943.5</td>\n",
       "      <td>2189.5</td>\n",
       "      <td>0.076494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Helsinki</td>\n",
       "      <td>90.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>22475.5</td>\n",
       "      <td>0.057521</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2017.5</td>\n",
       "      <td>1292.5</td>\n",
       "      <td>0.089854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dartmouth College</td>\n",
       "      <td>89.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>6162.0</td>\n",
       "      <td>0.150916</td>\n",
       "      <td>27.0</td>\n",
       "      <td>931.5</td>\n",
       "      <td>930.0</td>\n",
       "      <td>0.151191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cornell University</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>21877.0</td>\n",
       "      <td>0.243516</td>\n",
       "      <td>970.0</td>\n",
       "      <td>2473.5</td>\n",
       "      <td>5327.5</td>\n",
       "      <td>0.113064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Duke University</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>15288.0</td>\n",
       "      <td>0.203473</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3164.0</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>0.206999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rice University</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>6525.5</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>316.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>0.128854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Purdue University</td>\n",
       "      <td>60.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>38456.5</td>\n",
       "      <td>0.230185</td>\n",
       "      <td>1334.0</td>\n",
       "      <td>2737.5</td>\n",
       "      <td>8852.0</td>\n",
       "      <td>0.071299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Virginia</td>\n",
       "      <td>113.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>22807.5</td>\n",
       "      <td>0.104040</td>\n",
       "      <td>487.0</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>2392.5</td>\n",
       "      <td>0.109733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Columbia University</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>25816.0</td>\n",
       "      <td>0.321809</td>\n",
       "      <td>913.0</td>\n",
       "      <td>5273.5</td>\n",
       "      <td>8306.0</td>\n",
       "      <td>0.205525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>15822.0</td>\n",
       "      <td>0.247121</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>4033.0</td>\n",
       "      <td>3912.0</td>\n",
       "      <td>0.254456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yale University</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>12278.5</td>\n",
       "      <td>0.204540</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>3883.0</td>\n",
       "      <td>2510.5</td>\n",
       "      <td>0.315440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>University of Pittsburgh</td>\n",
       "      <td>100.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>26380.0</td>\n",
       "      <td>0.105640</td>\n",
       "      <td>572.0</td>\n",
       "      <td>4725.0</td>\n",
       "      <td>2786.5</td>\n",
       "      <td>0.179127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Northwestern University</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>18070.5</td>\n",
       "      <td>0.181620</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>2797.5</td>\n",
       "      <td>3282.5</td>\n",
       "      <td>0.152342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>University of Pennsylvania</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>20500.0</td>\n",
       "      <td>0.202960</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>4315.5</td>\n",
       "      <td>4161.0</td>\n",
       "      <td>0.210142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>University of Michigan</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>42482.5</td>\n",
       "      <td>0.167225</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>5835.5</td>\n",
       "      <td>7108.5</td>\n",
       "      <td>0.137044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>University of Washington</td>\n",
       "      <td>25.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>50959.0</td>\n",
       "      <td>0.153482</td>\n",
       "      <td>550.0</td>\n",
       "      <td>3213.0</td>\n",
       "      <td>7782.0</td>\n",
       "      <td>0.065659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Pennsylvania State University</td>\n",
       "      <td>77.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>45511.5</td>\n",
       "      <td>0.147622</td>\n",
       "      <td>211.0</td>\n",
       "      <td>3248.0</td>\n",
       "      <td>6719.0</td>\n",
       "      <td>0.071360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>University of Rochester</td>\n",
       "      <td>153.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>9636.0</td>\n",
       "      <td>0.290548</td>\n",
       "      <td>488.0</td>\n",
       "      <td>2404.5</td>\n",
       "      <td>2799.5</td>\n",
       "      <td>0.249581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Georgia Institute of Technology</td>\n",
       "      <td>33.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>20927.5</td>\n",
       "      <td>0.247916</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>5184.5</td>\n",
       "      <td>0.051026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>University of Illinois at Urbana-Champaign</td>\n",
       "      <td>37.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>42914.5</td>\n",
       "      <td>0.226757</td>\n",
       "      <td>259.0</td>\n",
       "      <td>2228.5</td>\n",
       "      <td>9732.5</td>\n",
       "      <td>0.052029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>University of Wisconsin-Madison</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>38972.5</td>\n",
       "      <td>0.123101</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>4681.5</td>\n",
       "      <td>4797.5</td>\n",
       "      <td>0.120116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Boston University</td>\n",
       "      <td>70.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>25247.5</td>\n",
       "      <td>0.262187</td>\n",
       "      <td>379.0</td>\n",
       "      <td>3022.0</td>\n",
       "      <td>6624.5</td>\n",
       "      <td>0.119651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>University of Florida</td>\n",
       "      <td>143.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>45915.5</td>\n",
       "      <td>0.095533</td>\n",
       "      <td>504.0</td>\n",
       "      <td>4033.5</td>\n",
       "      <td>4384.0</td>\n",
       "      <td>0.088141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>49.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>48278.0</td>\n",
       "      <td>0.099422</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>0.058753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Brown University</td>\n",
       "      <td>50.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>9074.5</td>\n",
       "      <td>0.198638</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>0.117154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>University of Maryland, College Park</td>\n",
       "      <td>69.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>33638.0</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>473.0</td>\n",
       "      <td>2922.5</td>\n",
       "      <td>3930.0</td>\n",
       "      <td>0.085508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington University in St Louis</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>13037.0</td>\n",
       "      <td>0.185416</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2189.5</td>\n",
       "      <td>2424.0</td>\n",
       "      <td>0.166823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>University of California, Davis</td>\n",
       "      <td>54.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>35804.5</td>\n",
       "      <td>0.116128</td>\n",
       "      <td>549.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>4132.5</td>\n",
       "      <td>0.092344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>University of Southern California</td>\n",
       "      <td>66.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>38564.5</td>\n",
       "      <td>0.233326</td>\n",
       "      <td>551.0</td>\n",
       "      <td>3061.0</td>\n",
       "      <td>8998.5</td>\n",
       "      <td>0.079373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>University of Minnesota</td>\n",
       "      <td>56.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>60345.5</td>\n",
       "      <td>0.109752</td>\n",
       "      <td>195.0</td>\n",
       "      <td>4210.5</td>\n",
       "      <td>6623.0</td>\n",
       "      <td>0.069904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Carnegie Mellon University</td>\n",
       "      <td>24.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>13016.0</td>\n",
       "      <td>0.464031</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>6044.5</td>\n",
       "      <td>0.087277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>98.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>12750.5</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>484.0</td>\n",
       "      <td>2717.0</td>\n",
       "      <td>2278.5</td>\n",
       "      <td>0.213232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       University  THE_rank  QS_rank  \\\n",
       "7                               Monash University      80.0     60.0   \n",
       "1                          University of Adelaide     134.0    109.0   \n",
       "3                        University of Queensland      65.0     47.0   \n",
       "5                 University of Western Australia     111.0     93.0   \n",
       "6                  Australian National University      48.0     20.0   \n",
       "0                   University of New South Wales      85.0     45.0   \n",
       "2                            University of Sydney      61.0     50.0   \n",
       "0                         University of Melbourne      32.0     41.0   \n",
       "0                            University of Vienna     165.0    154.0   \n",
       "0                                Ghent University     107.0    125.0   \n",
       "3                                       KU Leuven      47.0     71.0   \n",
       "1                Université Catholique de Louvain     129.0    153.0   \n",
       "5                               McGill University      42.0     32.0   \n",
       "0                           University of Alberta     119.0     90.0   \n",
       "1                  University of British Columbia      34.0     51.0   \n",
       "4                             McMaster University      78.0    140.0   \n",
       "0                          University of Montreal     108.0    130.0   \n",
       "3                           University of Toronto      22.0     31.0   \n",
       "5                             Zhejiang University     177.0     87.0   \n",
       "4   University of Science and Technology of China     132.0     97.0   \n",
       "2                                Fudan University     116.0     40.0   \n",
       "1                               Peking University      27.0     38.0   \n",
       "0                             Tsinghua University      30.0     25.0   \n",
       "6                   Shanghai Jiao Tong University     188.0     62.0   \n",
       "3                              Nanjing University     169.0    114.0   \n",
       "0                 Technical University of Denmark     153.0    116.0   \n",
       "2                               Aarhus University     109.0    119.0   \n",
       "1                        University of Copenhagen     109.0     73.0   \n",
       "1                                Aalto University     190.0    137.0   \n",
       "0                          University of Helsinki      90.0    102.0   \n",
       "..                                            ...       ...      ...   \n",
       "32                              Dartmouth College      89.0    169.0   \n",
       "31                             Cornell University      19.0     14.0   \n",
       "6                                 Duke University      17.0     21.0   \n",
       "5                                 Rice University      86.0     89.0   \n",
       "4                               Purdue University      60.0    105.0   \n",
       "3                          University of Virginia     113.0    173.0   \n",
       "2                             Columbia University      14.0     18.0   \n",
       "1                        Johns Hopkins University      13.0     17.0   \n",
       "0                                 Yale University      12.0     16.0   \n",
       "40                       University of Pittsburgh     100.0    142.0   \n",
       "61                        Northwestern University      20.0     28.0   \n",
       "41                     University of Pennsylvania      10.0     19.0   \n",
       "43                         University of Michigan      21.0     21.0   \n",
       "58                       University of Washington      25.0     61.0   \n",
       "57                  Pennsylvania State University      77.0     93.0   \n",
       "56                        University of Rochester     153.0    186.0   \n",
       "55                Georgia Institute of Technology      33.0     70.0   \n",
       "54     University of Illinois at Urbana-Champaign      37.0     69.0   \n",
       "53                University of Wisconsin-Madison      43.0     55.0   \n",
       "52                              Boston University      70.0     81.0   \n",
       "51                          University of Florida     143.0    178.0   \n",
       "50                  University of Texas at Austin      49.0     67.0   \n",
       "49                               Brown University      50.0     53.0   \n",
       "48           University of Maryland, College Park      69.0    129.0   \n",
       "47              Washington University in St Louis      50.0    100.0   \n",
       "46                University of California, Davis      54.0    118.0   \n",
       "45              University of Southern California      66.0    132.0   \n",
       "44                        University of Minnesota      56.0    163.0   \n",
       "42                     Carnegie Mellon University      24.0     47.0   \n",
       "34                               Emory University      98.0    147.0   \n",
       "\n",
       "          country         region  nb_stud_tot  int_stud_ratio  fac_memb_int  \\\n",
       "7       Australia        Oceania      52139.5        0.319148        1679.0   \n",
       "1       Australia        Oceania      21240.5        0.321008         633.0   \n",
       "3       Australia        Oceania      38232.5        0.268944        1870.0   \n",
       "5       Australia        Oceania      18659.0        0.248442         809.0   \n",
       "6       Australia        Oceania      15214.0        0.367183         927.0   \n",
       "0       Australia        Oceania      39958.5        0.349620        1612.0   \n",
       "2       Australia        Oceania      45615.5        0.342420        1829.0   \n",
       "0       Australia        Oceania      42149.0        0.413717        1477.0   \n",
       "0         Austria         Europe      40671.0        0.287374        1400.0   \n",
       "0         Belgium         Europe      35938.5        0.102352         482.0   \n",
       "3         Belgium         Europe      44975.0        0.151046         784.0   \n",
       "1         Belgium         Europe      24364.0        0.187021         406.0   \n",
       "5          Canada  North America      29888.5        0.295412        1220.0   \n",
       "0          Canada  North America      32100.0        0.259120        1294.0   \n",
       "1          Canada  North America      51119.5        0.258088        1635.0   \n",
       "4          Canada  North America      23697.5        0.149846        1170.0   \n",
       "0          Canada  North America      40064.5        0.233849        1037.0   \n",
       "3          Canada  North America      70817.0        0.236717        3905.0   \n",
       "5           China           Asia      45460.0        0.086583        1913.0   \n",
       "4           China           Asia      16032.0        0.032091         155.0   \n",
       "2           China           Asia      30997.0        0.130316        1178.0   \n",
       "1           China           Asia      42136.0        0.164132        1038.0   \n",
       "0           China           Asia      39194.5        0.101088         932.0   \n",
       "6           China           Asia      38109.5        0.066706         887.0   \n",
       "3           China           Asia      32975.5        0.095545         617.0   \n",
       "0         Denmark         Europe       8713.0        0.238157         966.0   \n",
       "2         Denmark         Europe      25696.5        0.131723         602.0   \n",
       "1         Denmark         Europe      31257.0        0.127334        2336.0   \n",
       "1         Finland         Europe      12445.5        0.175368         370.0   \n",
       "0         Finland         Europe      22475.5        0.057521         535.0   \n",
       "..            ...            ...          ...             ...           ...   \n",
       "32  United States  North America       6162.0        0.150916          27.0   \n",
       "31  United States  North America      21877.0        0.243516         970.0   \n",
       "6   United States  North America      15288.0        0.203473         226.0   \n",
       "5   United States  North America       6525.5        0.279713         316.0   \n",
       "4   United States  North America      38456.5        0.230185        1334.0   \n",
       "3   United States  North America      22807.5        0.104040         487.0   \n",
       "2   United States  North America      25816.0        0.321809         913.0   \n",
       "1   United States  North America      15822.0        0.247121        1061.0   \n",
       "0   United States  North America      12278.5        0.204540        1708.0   \n",
       "40  United States  North America      26380.0        0.105640         572.0   \n",
       "61  United States  North America      18070.5        0.181620        1141.0   \n",
       "41  United States  North America      20500.0        0.202960        1383.0   \n",
       "43  United States  North America      42482.5        0.167225        1920.0   \n",
       "58  United States  North America      50959.0        0.153482         550.0   \n",
       "57  United States  North America      45511.5        0.147622         211.0   \n",
       "56  United States  North America       9636.0        0.290548         488.0   \n",
       "55  United States  North America      20927.5        0.247916          75.0   \n",
       "54  United States  North America      42914.5        0.226757         259.0   \n",
       "53  United States  North America      38972.5        0.123101        1151.0   \n",
       "52  United States  North America      25247.5        0.262187         379.0   \n",
       "51  United States  North America      45915.5        0.095533         504.0   \n",
       "50  United States  North America      48278.0        0.099422         108.0   \n",
       "49  United States  North America       9074.5        0.198638         379.0   \n",
       "48  United States  North America      33638.0        0.115950         473.0   \n",
       "47  United States  North America      13037.0        0.185416         784.0   \n",
       "46  United States  North America      35804.5        0.116128         549.0   \n",
       "45  United States  North America      38564.5        0.233326         551.0   \n",
       "44  United States  North America      60345.5        0.109752         195.0   \n",
       "42  United States  North America      13016.0        0.464031         425.0   \n",
       "34  United States  North America      12750.5        0.178800         484.0   \n",
       "\n",
       "    fac_memb_tot  nb_stud_int  fac_memb_ratio  \n",
       "7         2297.0      16847.0        0.042730  \n",
       "1         1174.0       6818.0        0.055279  \n",
       "3         2124.5      10275.5        0.056116  \n",
       "5         1140.5       4635.5        0.061250  \n",
       "6         1214.0       5573.0        0.081301  \n",
       "0         2213.5      13968.5        0.055475  \n",
       "2         2711.0      15643.0        0.059139  \n",
       "0         2447.0      17438.0        0.058044  \n",
       "0         2555.5      11832.5        0.061141  \n",
       "0         1760.0       3678.0        0.048959  \n",
       "3         1856.0       6793.5        0.041091  \n",
       "1          932.5       4556.5        0.038334  \n",
       "5         2986.0       8792.0        0.100811  \n",
       "0         2531.0       8318.0        0.079200  \n",
       "1         3757.0      13217.5        0.073781  \n",
       "4         2095.0       3550.5        0.088402  \n",
       "0         2416.5       9355.5        0.060684  \n",
       "3         6646.5      16856.0        0.093082  \n",
       "5         4028.0       3814.0        0.090601  \n",
       "4         1973.5        514.0        0.123101  \n",
       "2         3376.0       3982.5        0.110603  \n",
       "1         4959.5       6915.5        0.117707  \n",
       "0         4289.0       3930.0        0.112337  \n",
       "6         3275.5       2547.5        0.085839  \n",
       "3         2402.5       3152.5        0.072894  \n",
       "0         1770.5       2074.5        0.202561  \n",
       "2         2037.5       3391.0        0.079120  \n",
       "1         7448.0       3969.0        0.238440  \n",
       "1          943.5       2189.5        0.076494  \n",
       "0         2017.5       1292.5        0.089854  \n",
       "..           ...          ...             ...  \n",
       "32         931.5        930.0        0.151191  \n",
       "31        2473.5       5327.5        0.113064  \n",
       "6         3164.0       3110.0        0.206999  \n",
       "5          842.0       1825.0        0.128854  \n",
       "4         2737.5       8852.0        0.071299  \n",
       "3         2494.0       2392.5        0.109733  \n",
       "2         5273.5       8306.0        0.205525  \n",
       "1         4033.0       3912.0        0.254456  \n",
       "0         3883.0       2510.5        0.315440  \n",
       "40        4725.0       2786.5        0.179127  \n",
       "61        2797.5       3282.5        0.152342  \n",
       "41        4315.5       4161.0        0.210142  \n",
       "43        5835.5       7108.5        0.137044  \n",
       "58        3213.0       7782.0        0.065659  \n",
       "57        3248.0       6719.0        0.071360  \n",
       "56        2404.5       2799.5        0.249581  \n",
       "55        1068.0       5184.5        0.051026  \n",
       "54        2228.5       9732.5        0.052029  \n",
       "53        4681.5       4797.5        0.120116  \n",
       "52        3022.0       6624.5        0.119651  \n",
       "51        4033.5       4384.0        0.088141  \n",
       "50        2836.0       4800.0        0.058753  \n",
       "49        1067.0       1802.0        0.117154  \n",
       "48        2922.5       3930.0        0.085508  \n",
       "47        2189.5       2424.0        0.166823  \n",
       "46        3275.0       4132.5        0.092344  \n",
       "45        3061.0       8998.5        0.079373  \n",
       "44        4210.5       6623.0        0.069904  \n",
       "42        1140.0       6044.5        0.087277  \n",
       "34        2717.0       2278.5        0.213232  \n",
       "\n",
       "[159 rows x 11 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
