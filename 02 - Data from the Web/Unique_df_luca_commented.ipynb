{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY FUNCTIONS --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return dataframes df1,df2 with only the rows where index in column1 exist also in column2 and vice versa\n",
    "# and also a third dataframe with the non mergeable rows.\n",
    "\n",
    "def exclude_differences(df1,df2,column1,column2):\n",
    "    tmp1 = df1[column1].value_counts().index\n",
    "    tmp2 = df2[column2].value_counts().index\n",
    "    my_diff = list(set(tmp1).symmetric_difference(set(tmp2)))\n",
    "    out_1 = df1.copy()\n",
    "    out_2 = df2.copy()\n",
    "    out_3 = out_1.iloc[0:0,:].copy()\n",
    "    \n",
    "    for loc in my_diff:\n",
    "        # we wanna keep track of non meargeable elements\n",
    "        out_31 = out_1[out_1[column1] == loc] \n",
    "        out_32 = out_2[out_2[column2] == loc]\n",
    "        out_3 = pd.concat([out_3, out_31])\n",
    "        out_3 = pd.concat([out_3, out_32])\n",
    "        # now we get rid of these rows\n",
    "        out_1 = out_1[out_1[column1] != loc] \n",
    "        out_2 = out_2[out_2[column2] != loc]\n",
    "                \n",
    "    return out_1, out_2, out_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merging_by_name(THE,QS,prob_limit):\n",
    "    # creating two lists with the names of the universities from the two datasets\n",
    "    the = THE.copy()\n",
    "    qs = QS.copy()\n",
    "    THE_name = list(the.loc[:,'THE_name'])\n",
    "    QS_name = list(qs.loc[:,'QS_name'])\n",
    "\n",
    "    #initializing a new column of the THE_df with the corresponding QS name found by the matching function\n",
    "    # just to control that everything went smoothly\n",
    "    the['THE_corresponding QS name'] = 'unknown'\n",
    "    the['prob'] = 'unknown'\n",
    "\n",
    "    # MATCHING FUNCTION\n",
    "    # finding the probable corresponding name in the QS dataframe for each university\n",
    "    for i,THE_uni in enumerate(THE_name):\n",
    "        QS_uni, prob=process.extractOne(THE_uni, QS_name, scorer=fuzz.token_sort_ratio)\n",
    "        if prob>=prob_limit: #if prob<87, I observed that the algorithm matches diffeent universities!! 97 is a good limit\n",
    "            the.loc[(the['THE_name']== THE_uni) , \"THE_corresponding QS name\"] = QS_uni\n",
    "            the.loc[(the['THE_name']== THE_uni) , 'prob'] = prob\n",
    "                     \n",
    "    # MERGING        \n",
    "    Unique_df=pd.merge(the,qs, left_on='THE_corresponding QS name', right_on='QS_name', how = 'outer')\n",
    "    return Unique_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_unique_df(THE,QS,prob):\n",
    "    unique_list = []\n",
    "    for loc in QS['country'].value_counts().sort_index().index:\n",
    "        the= THE.loc[THE['THE_location'] == loc , :].copy()\n",
    "        qs  = QS.loc[QS['country'] == loc , :].copy()\n",
    "        unique = merging_by_name(the,qs,prob)\n",
    "        unique = unique.dropna(axis=0,how='any')\n",
    "        unique_list.append(unique)\n",
    "    unique_out = pd.concat(unique_list)\n",
    "    return unique_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_matched_uni(df,name, list_of_matched_uni):\n",
    "    out = df.copy()\n",
    "    for x in out[name]:\n",
    "        if x in list_of_matched_uni:\n",
    "            out.drop(out[out[name] == x].index[0], inplace=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_to_non_mergeable(non_mergeable,THE,QS,errors_THE,errors_QS):\n",
    "    out = non_mergeable.copy()\n",
    "\n",
    "    for x in errors_THE:\n",
    "        out = pd.concat([out,THE.loc[THE['THE_name'] == x]])\n",
    "    for x in errors_QS:\n",
    "        out = pd.concat([out,QS.loc[QS['QS_name'] == x]])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next two functions are for text transformation improve fuzz accuracy, we first provide examples of how the libraries work:\n",
    "\n",
    "fuzz influenced by:  äàö _ \n",
    "\n",
    "fuzz not influenced by:  éè'-()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malaga \n",
      " Ecole Normale Superieure de Lyon \n",
      " Scuola Superiore Sant'Anna Pisa di Studi Universitari e di Perfezionamento\n",
      "aeaaeou_euE\n",
      "Malaga\n"
     ]
    }
   ],
   "source": [
    "# example of use for the library unidecode\n",
    "\n",
    "accented_string = 'Málaga'\n",
    "# accented_string is of type 'unicode'\n",
    "unaccented_string = unidecode.unidecode(accented_string)\n",
    "unaccented_string2 = unidecode.unidecode(string_tmp)\n",
    "# unaccented_string contains 'Malaga'and is of type 'str'\n",
    "print(unaccented_string,'\\n',unaccented_string2,'\\n',string_tmp2 )\n",
    "print(unidecode.unidecode('äèàäéöû_èüÈ'))\n",
    "print(unidecode.unidecode(accented_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 foe bar\n",
      "paris sorbonne university  paris 4\n",
      "scuola superiore sant anna pisa di studi universitari e di perfezionamento\n",
      "eo\n"
     ]
    }
   ],
   "source": [
    "# example of use for the collections library\n",
    "\n",
    "table = collections.defaultdict(lambda: None)\n",
    "table.update({\n",
    "    ord('é'):'e',\n",
    "    ord('ô'):'o',\n",
    "    ord('ö'):'o',\n",
    "    ord(' '):' ',\n",
    "    ord('\\''):' ',\n",
    "    ord('-'): ' ',\n",
    "    ord('\\N{NO-BREAK SPACE}'): ' ',\n",
    "    ord('\\N{EN SPACE}'): ' ',\n",
    "    ord('\\N{EM SPACE}'): ' ',\n",
    "    ord('\\N{THREE-PER-EM SPACE}'): ' ',\n",
    "    ord('\\N{FOUR-PER-EM SPACE}'): ' ',\n",
    "    ord('\\N{SIX-PER-EM SPACE}'): ' ',\n",
    "    ord('\\N{FIGURE SPACE}'): ' ',\n",
    "    ord('\\N{PUNCTUATION SPACE}'): ' ',\n",
    "    ord('\\N{THIN SPACE}'): ' ',\n",
    "    ord('\\N{HAIR SPACE}'): ' ',\n",
    "    ord('\\N{ZERO WIDTH SPACE}'): ' ',\n",
    "    ord('\\N{NARROW NO-BREAK SPACE}'): ' ',\n",
    "    ord('\\N{MEDIUM MATHEMATICAL SPACE}'): ' ',\n",
    "    ord('\\N{IDEOGRAPHIC SPACE}'): ' ',\n",
    "    ord('\\N{IDEOGRAPHIC HALF FILL SPACE}'): ' ',\n",
    "    ord('\\N{ZERO WIDTH NO-BREAK SPACE}'): ' ',\n",
    "    ord('\\N{TAG SPACE}'): ' ',\n",
    "    })\n",
    "table.update(dict(zip(map(ord,string.ascii_uppercase), string.ascii_lowercase)))\n",
    "table.update(dict(zip(map(ord,string.ascii_lowercase), string.ascii_lowercase)))\n",
    "table.update(dict(zip(map(ord,string.digits), string.digits)))\n",
    "\n",
    "print('123 fôé BAR҉'.translate(table,))\n",
    "print('Paris-Sorbonne University – Paris 4'.translate(table,))\n",
    "print(string_tmp2.translate(table,))\n",
    "print('éöàäèüÒàèò'.translate(table,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_accent_in_name(df,name):\n",
    "    out=df#.copy()\n",
    "    for x in out[name]:\n",
    "        x = unidecode.unidecode(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_characters_in_name(df,name):\n",
    "    out=df.copy()\n",
    "    for x in out[name]:\n",
    "        x = x.translate(table,)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Those where our dataset, from now we try to merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there is not the same set of countries in the two ranking. The universities that come from a country not present in the other dataset are thus considered not-mergeable. Note the we replaced \"Russian federation \" by \"Russia\" to have a match, assuming that they are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is my set of country present in only one of the rankings:\n",
      " ['Malaysia', 'Argentina', 'Chile', 'Brazil', 'India', 'Luxembourg', 'Israel', 'Saudi Arabia', 'Mexico']\n"
     ]
    }
   ],
   "source": [
    "# Set russian federation equal russia for comparing countries\n",
    "THE_df.loc[THE_df['THE_location']=='Russian Federation','THE_location']='Russia'\n",
    "\n",
    "# find differences in listed countries\n",
    "tmp1 = QS_df['country'].value_counts().index\n",
    "tmp2 = THE_df['THE_location'].value_counts().index\n",
    "my_diff = list(set(tmp1).symmetric_difference(set(tmp2)))\n",
    "print('Here is my set of country present in only one of the rankings:\\n',my_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 remove unis of countries that are not in both rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QS_df remaining rows:  187     THE_df remaining rows:  199\n",
      "Rows in non-mergeable:  14\n"
     ]
    }
   ],
   "source": [
    "QS_step1, THE_step1, non_mergeable = exclude_differences(QS_df,THE_df,'country','THE_location')\n",
    "\n",
    "print('QS_df remaining rows: ',QS_step1.shape[0],'    THE_df remaining rows: ',THE_step1.shape[0])\n",
    "print('Rows in non-mergeable: ',non_mergeable.shape[0])\n",
    "QS_step1.sort_values('country',inplace=True)\n",
    "THE_step1.sort_values('THE_location',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note that non_meargeable contains only a subset of all the non-meargeables rows, we will append rows to it as the analysis continues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 take out 100% fitting unis names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged rows at this step:  107\n",
      "Non mergeable dataframe #rows:  16\n",
      "THE before:  199    THE after:  92\n",
      "QS before:  187    QS after:  80\n"
     ]
    }
   ],
   "source": [
    "Unique_df = create_unique_df(THE_step1,QS_step1,100)\n",
    "\n",
    "# list of matched unis by ranking\n",
    "QS_matched_uni = list(Unique_df['QS_name'])\n",
    "THE_matched_uni = list(Unique_df['THE_name'])\n",
    "\n",
    "# update the remaining ranking dataframes\n",
    "THE_step2 = drop_matched_uni(THE_step1,'THE_name',THE_matched_uni)\n",
    "QS_step2 = drop_matched_uni(QS_step1,'QS_name', QS_matched_uni)\n",
    "\n",
    "# print to check that the dataframes have the correct size:\n",
    "print('merged rows at this step: ',Unique_df.shape[0])\n",
    "print('Non mergeable dataframe #rows: ',non_mergeable.shape[0])\n",
    "print('THE before: ',THE_step1.shape[0],'   THE after: ',THE_step2.shape[0])\n",
    "print('QS before: ',QS_step1.shape[0],'   QS after: ',QS_step2.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 go to 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged rows at this step:  37\n",
      "Non mergeable dataframe #rows:  16\n",
      "THE before:  92    THE after:  55\n",
      "QS before:  80    QS after:  43\n"
     ]
    }
   ],
   "source": [
    "THE_step2_tmp = remove_accent_in_name(THE_step2,'THE_name') # try to remove accents\n",
    "QS_step2_tmp = remove_accent_in_name(QS_step2,'QS_name') # but without succes\n",
    "\n",
    "Unique_df2 = create_unique_df(THE_step2_tmp,QS_step2_tmp,90) #90 since 100 gave nothing\n",
    "\n",
    "# list of matched unis by ranking (at this step)\n",
    "THE_matched_uni = list(Unique_df2['THE_name'])\n",
    "QS_matched_uni = list(Unique_df2['QS_name'])\n",
    "\n",
    "# update the remaining ranking dataframes\n",
    "THE_step3 = drop_matched_uni(THE_step2,'THE_name',THE_matched_uni)\n",
    "QS_step3 = drop_matched_uni(QS_step2,'QS_name', QS_matched_uni)\n",
    "\n",
    "# usual cross check\n",
    "print('merged rows at this step: ',Unique_df2.shape[0])\n",
    "print('Non mergeable dataframe #rows: ',non_mergeable.shape[0])\n",
    "print('THE before: ',THE_step2.shape[0],'   THE after: ',THE_step3.shape[0])\n",
    "print('QS before: ',QS_step2.shape[0],'   QS after: ',QS_step3.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 go to 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged rows at this step:  8\n",
      "Non mergeable dataframe #rows:  16\n",
      "THE before:  55    THE after:  46\n",
      "QS before:  43    QS after:  34\n"
     ]
    }
   ],
   "source": [
    "THE_step3_tmp = remove_characters_in_name(THE_step3,'THE_name') # tried to remove special characters\n",
    "QS_step3_tmp = remove_characters_in_name(QS_step3,'QS_name') # doesn't work though\n",
    "\n",
    "Unique_df3 = create_unique_df(THE_step3_tmp,QS_step3_tmp,80) \n",
    "\n",
    "# errors made\n",
    "errors = [\"Trinity College Dublin\",'University College Dublin']\n",
    "\n",
    "# update the non-mergeable dataframe\n",
    "non_mergeable = pd.concat([non_mergeable,THE_step3.loc[THE_step3['THE_name'] == \"Trinity College Dublin\"]]) \n",
    "non_mergeable = pd.concat([non_mergeable,QS_step3.loc[QS_step3['QS_name'] == \"University College Dublin\"]]) \n",
    "\n",
    "Unique_df3 = Unique_df3.loc[Unique_df3['THE_name'] != \"Trinity College Dublin\"] #the only one with an error\n",
    "\n",
    "# list of matched unis by ranking (at this step)\n",
    "THE_matched_uni = list(Unique_df3['THE_name'])  + errors\n",
    "QS_matched_uni = list(Unique_df3['QS_name']) + errors\n",
    "\n",
    "# update the remaining ranking dataframes\n",
    "THE_step4 = drop_matched_uni(THE_step3,'THE_name',THE_matched_uni)\n",
    "QS_step4 = drop_matched_uni(QS_step3,'QS_name', QS_matched_uni)\n",
    "\n",
    "# remove duplicates ()usefull mainly if we runs multiples times this cell\n",
    "non_mergeable = non_mergeable.drop_duplicates()\n",
    "\n",
    "# usual cross check \n",
    "print('merged rows at this step: ',Unique_df3.shape[0])\n",
    "print('Non mergeable dataframe #rows: ',non_mergeable.shape[0])\n",
    "print('THE before: ',THE_step3.shape[0],'   THE after: ',THE_step4.shape[0])\n",
    "print('QS before: ',QS_step3.shape[0],'   QS after: ',QS_step4.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5 go to 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged rows at this step:  3\n",
      "Non mergeable dataframe #rows:  22\n",
      "THE before:  46    THE after:  39\n",
      "QS before:  34    QS after:  29\n"
     ]
    }
   ],
   "source": [
    "# df created with the matching function, but some errors are present\n",
    "Unique_df4 = create_unique_df(THE_step4,QS_step4,70) \n",
    "\n",
    "# errors at this step\n",
    "errors = ['University of Sussex','University of Reading',\\\n",
    "          'University of East Anglia','University of Bath',\\\n",
    "          'University of Leicester','University of Dundee']\n",
    "\n",
    "# errors by ranking\n",
    "errors_THE = ['University of Sussex','University of East Anglia','University of Dundee','University of Leicester']\n",
    "errors_QS = ['University of Reading','University of Bath']\n",
    "\n",
    "# clean the unique_df from its errors\n",
    "for x in Unique_df4['QS_name']:\n",
    "    if x in errors:\n",
    "        Unique_df4 = Unique_df4[Unique_df4['QS_name'] != x]\n",
    "for x in Unique_df4['THE_name']:\n",
    "    if x in errors:\n",
    "        Unique_df4 = Unique_df4[Unique_df4['THE_name'] != x]\n",
    "\n",
    "#update non mergeable df\n",
    "non_mergeable = append_to_non_mergeable(non_mergeable,THE_step4,QS_step4,\\\n",
    "                                                    errors_THE,errors_QS)\n",
    "#drop duplicates\n",
    "non_mergeable = non_mergeable.drop_duplicates()\n",
    "\n",
    "# list of matched unis by ranking (at this step)\n",
    "THE_matched_uni = list(Unique_df4['THE_name'])  + errors_THE\n",
    "QS_matched_uni = list(Unique_df4['QS_name']) + errors_QS\n",
    "\n",
    "# update the remaining ranking dataframes\n",
    "THE_step5 = drop_matched_uni(THE_step4,'THE_name',THE_matched_uni)\n",
    "QS_step5 = drop_matched_uni(QS_step4,'QS_name', QS_matched_uni)\n",
    "\n",
    "# usual cross check \n",
    "print('merged rows at this step: ',Unique_df4.shape[0])\n",
    "print('Non mergeable dataframe #rows: ',non_mergeable.shape[0])\n",
    "print('THE before: ',THE_step4.shape[0],'   THE after: ',THE_step5.shape[0])\n",
    "print('QS before: ',QS_step4.shape[0],'   QS after: ',QS_step5.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final STEP all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged rows at this step:  4\n",
      "Non mergeable dataframe #rows:  82\n",
      "THE before:  39    THE after:  35\n",
      "QS before:  29    QS after:  25\n"
     ]
    }
   ],
   "source": [
    "# create merged dataframe with matching function. But some errors are present\n",
    "Unique_df5 = create_unique_df(THE_step5,QS_step5,10)\n",
    "\n",
    "# correct matchings for THE_ranking (since they are unique due to our merging function)\n",
    "rights = ['University of Tübingen','LMU Munich','University of Freiburg','Scuola Superiore Sant’Anna']\n",
    "\n",
    "# errors made: (incorrect matching)\n",
    "errors = list(set(rights).symmetric_difference(set(list(Unique_df5['THE_name']))))\n",
    "\n",
    "for x in errors:\n",
    "    Unique_df5 = Unique_df5[Unique_df5['THE_name'] != x] \n",
    "\n",
    "\n",
    "# list of matched unis by ranking (at this step)\n",
    "THE_matched_uni = list(Unique_df5['THE_name']) \n",
    "QS_matched_uni = list(Unique_df5['QS_name']) \n",
    "\n",
    "# update the remaining ranking dataframes\n",
    "THE_step6 = drop_matched_uni(THE_step5,'THE_name',THE_matched_uni)\n",
    "QS_step6 = drop_matched_uni(QS_step5,'QS_name', QS_matched_uni)\n",
    "\n",
    "# update non_mergeables unis dataframe\n",
    "non_mergeable = pd.concat([non_mergeable,THE_step6,QS_step6])\n",
    "non_mergeable = non_mergeable.drop_duplicates()\n",
    "\n",
    "# usual cross check \n",
    "print('merged rows at this step: ',Unique_df5.shape[0])\n",
    "print('Non mergeable dataframe #rows: ',non_mergeable.shape[0])\n",
    "print('THE before: ',THE_step5.shape[0],'   THE after: ',THE_step6.shape[0])\n",
    "print('QS before: ',QS_step5.shape[0],'   QS after: ',QS_step6.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final check: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged:  159   non-merged 82 \n",
      "missing 0\n",
      "\n",
      "if 0 missing, it is probable the merge is successfull\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.concat([Unique_df,Unique_df2,Unique_df3,Unique_df4,Unique_df5])\n",
    "num_merged = merged_df.shape[0]\n",
    "\n",
    "non_mergeable = non_mergeable.drop_duplicates()\n",
    "num_non_merged = non_mergeable.shape[0]\n",
    "print ('merged: ',num_merged,'  non-merged',num_non_merged,'\\nmissing',(200-num_merged)*2-num_non_merged)\n",
    "print('\\nif 0 missing, it is probable the merge is successfull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
